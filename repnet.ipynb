{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('./xclip'))\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from xclip.models.repnet import RepNet\n",
    "from xclip.models.cct import CrossFrameCommunicationTransformer\n",
    "from xclip.models.cct import load\n",
    "from xclip.utils.logger import create_logger\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIDES = [1,2,3]\n",
    "VIDEO_PATH = \"/Users/kanantharaman/Downloads/detectron/Data/videos/test/push-up/push-up_5.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=0.5, std=0.5),\n",
    "    ])\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "raw_frames, frames = [], []\n",
    "while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "        raw_frames.append(frame)\n",
    "        frame = transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepNet(\n",
       "  (tsm_conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (period_length_head): Sequential(\n",
       "    (0): TranformerLayer(\n",
       "      (input_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=32, bias=True)\n",
       "  )\n",
       "  (periodicity_head): Sequential(\n",
       "    (0): TranformerLayer(\n",
       "      (input_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RepNet()\n",
    "state_dict = torch.load('./xclip/repnet_weights.pth', map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict1 = torch.load('./xclip/best.pth', map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['positional_embedding', 'text_projection', 'logit_scale', 'prompts_visual_proj', 'prompts_generator.alpha', 'prompts_generator.norm.weight', 'prompts_generator.norm.bias', 'prompts_generator.decoder.0.cross_attn.q_proj.weight', 'prompts_generator.decoder.0.cross_attn.k_proj.weight', 'prompts_generator.decoder.0.cross_attn.v_proj.weight', 'prompts_generator.decoder.0.cross_attn.proj.weight', 'prompts_generator.decoder.0.cross_attn.proj.bias', 'prompts_generator.decoder.0.norm1.weight', 'prompts_generator.decoder.0.norm1.bias', 'prompts_generator.decoder.0.norm3.weight', 'prompts_generator.decoder.0.norm3.bias', 'prompts_generator.decoder.0.mlp.0.weight', 'prompts_generator.decoder.0.mlp.0.bias', 'prompts_generator.decoder.0.mlp.3.weight', 'prompts_generator.decoder.0.mlp.3.bias', 'prompts_generator.decoder.1.cross_attn.q_proj.weight', 'prompts_generator.decoder.1.cross_attn.k_proj.weight', 'prompts_generator.decoder.1.cross_attn.v_proj.weight', 'prompts_generator.decoder.1.cross_attn.proj.weight', 'prompts_generator.decoder.1.cross_attn.proj.bias', 'prompts_generator.decoder.1.norm1.weight', 'prompts_generator.decoder.1.norm1.bias', 'prompts_generator.decoder.1.norm3.weight', 'prompts_generator.decoder.1.norm3.bias', 'prompts_generator.decoder.1.mlp.0.weight', 'prompts_generator.decoder.1.mlp.0.bias', 'prompts_generator.decoder.1.mlp.3.weight', 'prompts_generator.decoder.1.mlp.3.bias', 'mit.positional_embedding', 'mit.resblocks.0.attn.in_proj_weight', 'mit.resblocks.0.attn.in_proj_bias', 'mit.resblocks.0.attn.out_proj.weight', 'mit.resblocks.0.attn.out_proj.bias', 'mit.resblocks.0.ln_1.weight', 'mit.resblocks.0.ln_1.bias', 'mit.resblocks.0.mlp.c_fc.weight', 'mit.resblocks.0.mlp.c_fc.bias', 'mit.resblocks.0.mlp.c_proj.weight', 'mit.resblocks.0.mlp.c_proj.bias', 'mit.resblocks.0.ln_2.weight', 'mit.resblocks.0.ln_2.bias', 'visual.class_embedding', 'visual.positional_embedding', 'visual.proj', 'visual.conv1.weight', 'visual.ln_pre.weight', 'visual.ln_pre.bias', 'visual.transformer.resblocks.0.message_fc.weight', 'visual.transformer.resblocks.0.message_fc.bias', 'visual.transformer.resblocks.0.message_ln.weight', 'visual.transformer.resblocks.0.message_ln.bias', 'visual.transformer.resblocks.0.message_attn.in_proj_weight', 'visual.transformer.resblocks.0.message_attn.in_proj_bias', 'visual.transformer.resblocks.0.message_attn.out_proj.weight', 'visual.transformer.resblocks.0.message_attn.out_proj.bias', 'visual.transformer.resblocks.0.attn.in_proj_weight', 'visual.transformer.resblocks.0.attn.in_proj_bias', 'visual.transformer.resblocks.0.attn.out_proj.weight', 'visual.transformer.resblocks.0.attn.out_proj.bias', 'visual.transformer.resblocks.0.ln_1.weight', 'visual.transformer.resblocks.0.ln_1.bias', 'visual.transformer.resblocks.0.mlp.c_fc.weight', 'visual.transformer.resblocks.0.mlp.c_fc.bias', 'visual.transformer.resblocks.0.mlp.c_proj.weight', 'visual.transformer.resblocks.0.mlp.c_proj.bias', 'visual.transformer.resblocks.0.ln_2.weight', 'visual.transformer.resblocks.0.ln_2.bias', 'visual.transformer.resblocks.1.message_fc.weight', 'visual.transformer.resblocks.1.message_fc.bias', 'visual.transformer.resblocks.1.message_ln.weight', 'visual.transformer.resblocks.1.message_ln.bias', 'visual.transformer.resblocks.1.message_attn.in_proj_weight', 'visual.transformer.resblocks.1.message_attn.in_proj_bias', 'visual.transformer.resblocks.1.message_attn.out_proj.weight', 'visual.transformer.resblocks.1.message_attn.out_proj.bias', 'visual.transformer.resblocks.1.attn.in_proj_weight', 'visual.transformer.resblocks.1.attn.in_proj_bias', 'visual.transformer.resblocks.1.attn.out_proj.weight', 'visual.transformer.resblocks.1.attn.out_proj.bias', 'visual.transformer.resblocks.1.ln_1.weight', 'visual.transformer.resblocks.1.ln_1.bias', 'visual.transformer.resblocks.1.mlp.c_fc.weight', 'visual.transformer.resblocks.1.mlp.c_fc.bias', 'visual.transformer.resblocks.1.mlp.c_proj.weight', 'visual.transformer.resblocks.1.mlp.c_proj.bias', 'visual.transformer.resblocks.1.ln_2.weight', 'visual.transformer.resblocks.1.ln_2.bias', 'visual.transformer.resblocks.2.message_fc.weight', 'visual.transformer.resblocks.2.message_fc.bias', 'visual.transformer.resblocks.2.message_ln.weight', 'visual.transformer.resblocks.2.message_ln.bias', 'visual.transformer.resblocks.2.message_attn.in_proj_weight', 'visual.transformer.resblocks.2.message_attn.in_proj_bias', 'visual.transformer.resblocks.2.message_attn.out_proj.weight', 'visual.transformer.resblocks.2.message_attn.out_proj.bias', 'visual.transformer.resblocks.2.attn.in_proj_weight', 'visual.transformer.resblocks.2.attn.in_proj_bias', 'visual.transformer.resblocks.2.attn.out_proj.weight', 'visual.transformer.resblocks.2.attn.out_proj.bias', 'visual.transformer.resblocks.2.ln_1.weight', 'visual.transformer.resblocks.2.ln_1.bias', 'visual.transformer.resblocks.2.mlp.c_fc.weight', 'visual.transformer.resblocks.2.mlp.c_fc.bias', 'visual.transformer.resblocks.2.mlp.c_proj.weight', 'visual.transformer.resblocks.2.mlp.c_proj.bias', 'visual.transformer.resblocks.2.ln_2.weight', 'visual.transformer.resblocks.2.ln_2.bias', 'visual.transformer.resblocks.3.message_fc.weight', 'visual.transformer.resblocks.3.message_fc.bias', 'visual.transformer.resblocks.3.message_ln.weight', 'visual.transformer.resblocks.3.message_ln.bias', 'visual.transformer.resblocks.3.message_attn.in_proj_weight', 'visual.transformer.resblocks.3.message_attn.in_proj_bias', 'visual.transformer.resblocks.3.message_attn.out_proj.weight', 'visual.transformer.resblocks.3.message_attn.out_proj.bias', 'visual.transformer.resblocks.3.attn.in_proj_weight', 'visual.transformer.resblocks.3.attn.in_proj_bias', 'visual.transformer.resblocks.3.attn.out_proj.weight', 'visual.transformer.resblocks.3.attn.out_proj.bias', 'visual.transformer.resblocks.3.ln_1.weight', 'visual.transformer.resblocks.3.ln_1.bias', 'visual.transformer.resblocks.3.mlp.c_fc.weight', 'visual.transformer.resblocks.3.mlp.c_fc.bias', 'visual.transformer.resblocks.3.mlp.c_proj.weight', 'visual.transformer.resblocks.3.mlp.c_proj.bias', 'visual.transformer.resblocks.3.ln_2.weight', 'visual.transformer.resblocks.3.ln_2.bias', 'visual.transformer.resblocks.4.message_fc.weight', 'visual.transformer.resblocks.4.message_fc.bias', 'visual.transformer.resblocks.4.message_ln.weight', 'visual.transformer.resblocks.4.message_ln.bias', 'visual.transformer.resblocks.4.message_attn.in_proj_weight', 'visual.transformer.resblocks.4.message_attn.in_proj_bias', 'visual.transformer.resblocks.4.message_attn.out_proj.weight', 'visual.transformer.resblocks.4.message_attn.out_proj.bias', 'visual.transformer.resblocks.4.attn.in_proj_weight', 'visual.transformer.resblocks.4.attn.in_proj_bias', 'visual.transformer.resblocks.4.attn.out_proj.weight', 'visual.transformer.resblocks.4.attn.out_proj.bias', 'visual.transformer.resblocks.4.ln_1.weight', 'visual.transformer.resblocks.4.ln_1.bias', 'visual.transformer.resblocks.4.mlp.c_fc.weight', 'visual.transformer.resblocks.4.mlp.c_fc.bias', 'visual.transformer.resblocks.4.mlp.c_proj.weight', 'visual.transformer.resblocks.4.mlp.c_proj.bias', 'visual.transformer.resblocks.4.ln_2.weight', 'visual.transformer.resblocks.4.ln_2.bias', 'visual.transformer.resblocks.5.message_fc.weight', 'visual.transformer.resblocks.5.message_fc.bias', 'visual.transformer.resblocks.5.message_ln.weight', 'visual.transformer.resblocks.5.message_ln.bias', 'visual.transformer.resblocks.5.message_attn.in_proj_weight', 'visual.transformer.resblocks.5.message_attn.in_proj_bias', 'visual.transformer.resblocks.5.message_attn.out_proj.weight', 'visual.transformer.resblocks.5.message_attn.out_proj.bias', 'visual.transformer.resblocks.5.attn.in_proj_weight', 'visual.transformer.resblocks.5.attn.in_proj_bias', 'visual.transformer.resblocks.5.attn.out_proj.weight', 'visual.transformer.resblocks.5.attn.out_proj.bias', 'visual.transformer.resblocks.5.ln_1.weight', 'visual.transformer.resblocks.5.ln_1.bias', 'visual.transformer.resblocks.5.mlp.c_fc.weight', 'visual.transformer.resblocks.5.mlp.c_fc.bias', 'visual.transformer.resblocks.5.mlp.c_proj.weight', 'visual.transformer.resblocks.5.mlp.c_proj.bias', 'visual.transformer.resblocks.5.ln_2.weight', 'visual.transformer.resblocks.5.ln_2.bias', 'visual.transformer.resblocks.6.message_fc.weight', 'visual.transformer.resblocks.6.message_fc.bias', 'visual.transformer.resblocks.6.message_ln.weight', 'visual.transformer.resblocks.6.message_ln.bias', 'visual.transformer.resblocks.6.message_attn.in_proj_weight', 'visual.transformer.resblocks.6.message_attn.in_proj_bias', 'visual.transformer.resblocks.6.message_attn.out_proj.weight', 'visual.transformer.resblocks.6.message_attn.out_proj.bias', 'visual.transformer.resblocks.6.attn.in_proj_weight', 'visual.transformer.resblocks.6.attn.in_proj_bias', 'visual.transformer.resblocks.6.attn.out_proj.weight', 'visual.transformer.resblocks.6.attn.out_proj.bias', 'visual.transformer.resblocks.6.ln_1.weight', 'visual.transformer.resblocks.6.ln_1.bias', 'visual.transformer.resblocks.6.mlp.c_fc.weight', 'visual.transformer.resblocks.6.mlp.c_fc.bias', 'visual.transformer.resblocks.6.mlp.c_proj.weight', 'visual.transformer.resblocks.6.mlp.c_proj.bias', 'visual.transformer.resblocks.6.ln_2.weight', 'visual.transformer.resblocks.6.ln_2.bias', 'visual.transformer.resblocks.7.message_fc.weight', 'visual.transformer.resblocks.7.message_fc.bias', 'visual.transformer.resblocks.7.message_ln.weight', 'visual.transformer.resblocks.7.message_ln.bias', 'visual.transformer.resblocks.7.message_attn.in_proj_weight', 'visual.transformer.resblocks.7.message_attn.in_proj_bias', 'visual.transformer.resblocks.7.message_attn.out_proj.weight', 'visual.transformer.resblocks.7.message_attn.out_proj.bias', 'visual.transformer.resblocks.7.attn.in_proj_weight', 'visual.transformer.resblocks.7.attn.in_proj_bias', 'visual.transformer.resblocks.7.attn.out_proj.weight', 'visual.transformer.resblocks.7.attn.out_proj.bias', 'visual.transformer.resblocks.7.ln_1.weight', 'visual.transformer.resblocks.7.ln_1.bias', 'visual.transformer.resblocks.7.mlp.c_fc.weight', 'visual.transformer.resblocks.7.mlp.c_fc.bias', 'visual.transformer.resblocks.7.mlp.c_proj.weight', 'visual.transformer.resblocks.7.mlp.c_proj.bias', 'visual.transformer.resblocks.7.ln_2.weight', 'visual.transformer.resblocks.7.ln_2.bias', 'visual.transformer.resblocks.8.message_fc.weight', 'visual.transformer.resblocks.8.message_fc.bias', 'visual.transformer.resblocks.8.message_ln.weight', 'visual.transformer.resblocks.8.message_ln.bias', 'visual.transformer.resblocks.8.message_attn.in_proj_weight', 'visual.transformer.resblocks.8.message_attn.in_proj_bias', 'visual.transformer.resblocks.8.message_attn.out_proj.weight', 'visual.transformer.resblocks.8.message_attn.out_proj.bias', 'visual.transformer.resblocks.8.attn.in_proj_weight', 'visual.transformer.resblocks.8.attn.in_proj_bias', 'visual.transformer.resblocks.8.attn.out_proj.weight', 'visual.transformer.resblocks.8.attn.out_proj.bias', 'visual.transformer.resblocks.8.ln_1.weight', 'visual.transformer.resblocks.8.ln_1.bias', 'visual.transformer.resblocks.8.mlp.c_fc.weight', 'visual.transformer.resblocks.8.mlp.c_fc.bias', 'visual.transformer.resblocks.8.mlp.c_proj.weight', 'visual.transformer.resblocks.8.mlp.c_proj.bias', 'visual.transformer.resblocks.8.ln_2.weight', 'visual.transformer.resblocks.8.ln_2.bias', 'visual.transformer.resblocks.9.message_fc.weight', 'visual.transformer.resblocks.9.message_fc.bias', 'visual.transformer.resblocks.9.message_ln.weight', 'visual.transformer.resblocks.9.message_ln.bias', 'visual.transformer.resblocks.9.message_attn.in_proj_weight', 'visual.transformer.resblocks.9.message_attn.in_proj_bias', 'visual.transformer.resblocks.9.message_attn.out_proj.weight', 'visual.transformer.resblocks.9.message_attn.out_proj.bias', 'visual.transformer.resblocks.9.attn.in_proj_weight', 'visual.transformer.resblocks.9.attn.in_proj_bias', 'visual.transformer.resblocks.9.attn.out_proj.weight', 'visual.transformer.resblocks.9.attn.out_proj.bias', 'visual.transformer.resblocks.9.ln_1.weight', 'visual.transformer.resblocks.9.ln_1.bias', 'visual.transformer.resblocks.9.mlp.c_fc.weight', 'visual.transformer.resblocks.9.mlp.c_fc.bias', 'visual.transformer.resblocks.9.mlp.c_proj.weight', 'visual.transformer.resblocks.9.mlp.c_proj.bias', 'visual.transformer.resblocks.9.ln_2.weight', 'visual.transformer.resblocks.9.ln_2.bias', 'visual.transformer.resblocks.10.message_fc.weight', 'visual.transformer.resblocks.10.message_fc.bias', 'visual.transformer.resblocks.10.message_ln.weight', 'visual.transformer.resblocks.10.message_ln.bias', 'visual.transformer.resblocks.10.message_attn.in_proj_weight', 'visual.transformer.resblocks.10.message_attn.in_proj_bias', 'visual.transformer.resblocks.10.message_attn.out_proj.weight', 'visual.transformer.resblocks.10.message_attn.out_proj.bias', 'visual.transformer.resblocks.10.attn.in_proj_weight', 'visual.transformer.resblocks.10.attn.in_proj_bias', 'visual.transformer.resblocks.10.attn.out_proj.weight', 'visual.transformer.resblocks.10.attn.out_proj.bias', 'visual.transformer.resblocks.10.ln_1.weight', 'visual.transformer.resblocks.10.ln_1.bias', 'visual.transformer.resblocks.10.mlp.c_fc.weight', 'visual.transformer.resblocks.10.mlp.c_fc.bias', 'visual.transformer.resblocks.10.mlp.c_proj.weight', 'visual.transformer.resblocks.10.mlp.c_proj.bias', 'visual.transformer.resblocks.10.ln_2.weight', 'visual.transformer.resblocks.10.ln_2.bias', 'visual.transformer.resblocks.11.message_fc.weight', 'visual.transformer.resblocks.11.message_fc.bias', 'visual.transformer.resblocks.11.message_ln.weight', 'visual.transformer.resblocks.11.message_ln.bias', 'visual.transformer.resblocks.11.message_attn.in_proj_weight', 'visual.transformer.resblocks.11.message_attn.in_proj_bias', 'visual.transformer.resblocks.11.message_attn.out_proj.weight', 'visual.transformer.resblocks.11.message_attn.out_proj.bias', 'visual.transformer.resblocks.11.attn.in_proj_weight', 'visual.transformer.resblocks.11.attn.in_proj_bias', 'visual.transformer.resblocks.11.attn.out_proj.weight', 'visual.transformer.resblocks.11.attn.out_proj.bias', 'visual.transformer.resblocks.11.ln_1.weight', 'visual.transformer.resblocks.11.ln_1.bias', 'visual.transformer.resblocks.11.mlp.c_fc.weight', 'visual.transformer.resblocks.11.mlp.c_fc.bias', 'visual.transformer.resblocks.11.mlp.c_proj.weight', 'visual.transformer.resblocks.11.mlp.c_proj.bias', 'visual.transformer.resblocks.11.ln_2.weight', 'visual.transformer.resblocks.11.ln_2.bias', 'visual.ln_post.weight', 'visual.ln_post.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'token_embedding.weight', 'ln_final.weight', 'ln_final.bias', 'prompts_visual_ln.weight', 'prompts_visual_ln.bias'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict1['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-10-31 14:48:25 root]\u001b[0m\u001b[33m(cct.py 168)\u001b[0m: INFO load pretrained CLIP: _IncompatibleKeys(missing_keys=['class_embedding', 'positional_embedding', 'proj', 'conv1.weight', 'ln_pre.weight', 'ln_pre.bias', 'transformer.resblocks.0.message_fc.weight', 'transformer.resblocks.0.message_fc.bias', 'transformer.resblocks.0.message_ln.weight', 'transformer.resblocks.0.message_ln.bias', 'transformer.resblocks.0.message_attn.in_proj_weight', 'transformer.resblocks.0.message_attn.in_proj_bias', 'transformer.resblocks.0.message_attn.out_proj.weight', 'transformer.resblocks.0.message_attn.out_proj.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.message_fc.weight', 'transformer.resblocks.1.message_fc.bias', 'transformer.resblocks.1.message_ln.weight', 'transformer.resblocks.1.message_ln.bias', 'transformer.resblocks.1.message_attn.in_proj_weight', 'transformer.resblocks.1.message_attn.in_proj_bias', 'transformer.resblocks.1.message_attn.out_proj.weight', 'transformer.resblocks.1.message_attn.out_proj.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.message_fc.weight', 'transformer.resblocks.2.message_fc.bias', 'transformer.resblocks.2.message_ln.weight', 'transformer.resblocks.2.message_ln.bias', 'transformer.resblocks.2.message_attn.in_proj_weight', 'transformer.resblocks.2.message_attn.in_proj_bias', 'transformer.resblocks.2.message_attn.out_proj.weight', 'transformer.resblocks.2.message_attn.out_proj.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.message_fc.weight', 'transformer.resblocks.3.message_fc.bias', 'transformer.resblocks.3.message_ln.weight', 'transformer.resblocks.3.message_ln.bias', 'transformer.resblocks.3.message_attn.in_proj_weight', 'transformer.resblocks.3.message_attn.in_proj_bias', 'transformer.resblocks.3.message_attn.out_proj.weight', 'transformer.resblocks.3.message_attn.out_proj.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.message_fc.weight', 'transformer.resblocks.4.message_fc.bias', 'transformer.resblocks.4.message_ln.weight', 'transformer.resblocks.4.message_ln.bias', 'transformer.resblocks.4.message_attn.in_proj_weight', 'transformer.resblocks.4.message_attn.in_proj_bias', 'transformer.resblocks.4.message_attn.out_proj.weight', 'transformer.resblocks.4.message_attn.out_proj.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.message_fc.weight', 'transformer.resblocks.5.message_fc.bias', 'transformer.resblocks.5.message_ln.weight', 'transformer.resblocks.5.message_ln.bias', 'transformer.resblocks.5.message_attn.in_proj_weight', 'transformer.resblocks.5.message_attn.in_proj_bias', 'transformer.resblocks.5.message_attn.out_proj.weight', 'transformer.resblocks.5.message_attn.out_proj.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.message_fc.weight', 'transformer.resblocks.6.message_fc.bias', 'transformer.resblocks.6.message_ln.weight', 'transformer.resblocks.6.message_ln.bias', 'transformer.resblocks.6.message_attn.in_proj_weight', 'transformer.resblocks.6.message_attn.in_proj_bias', 'transformer.resblocks.6.message_attn.out_proj.weight', 'transformer.resblocks.6.message_attn.out_proj.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.message_fc.weight', 'transformer.resblocks.7.message_fc.bias', 'transformer.resblocks.7.message_ln.weight', 'transformer.resblocks.7.message_ln.bias', 'transformer.resblocks.7.message_attn.in_proj_weight', 'transformer.resblocks.7.message_attn.in_proj_bias', 'transformer.resblocks.7.message_attn.out_proj.weight', 'transformer.resblocks.7.message_attn.out_proj.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.message_fc.weight', 'transformer.resblocks.8.message_fc.bias', 'transformer.resblocks.8.message_ln.weight', 'transformer.resblocks.8.message_ln.bias', 'transformer.resblocks.8.message_attn.in_proj_weight', 'transformer.resblocks.8.message_attn.in_proj_bias', 'transformer.resblocks.8.message_attn.out_proj.weight', 'transformer.resblocks.8.message_attn.out_proj.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.message_fc.weight', 'transformer.resblocks.9.message_fc.bias', 'transformer.resblocks.9.message_ln.weight', 'transformer.resblocks.9.message_ln.bias', 'transformer.resblocks.9.message_attn.in_proj_weight', 'transformer.resblocks.9.message_attn.in_proj_bias', 'transformer.resblocks.9.message_attn.out_proj.weight', 'transformer.resblocks.9.message_attn.out_proj.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.message_fc.weight', 'transformer.resblocks.10.message_fc.bias', 'transformer.resblocks.10.message_ln.weight', 'transformer.resblocks.10.message_ln.bias', 'transformer.resblocks.10.message_attn.in_proj_weight', 'transformer.resblocks.10.message_attn.in_proj_bias', 'transformer.resblocks.10.message_attn.out_proj.weight', 'transformer.resblocks.10.message_attn.out_proj.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.message_fc.weight', 'transformer.resblocks.11.message_fc.bias', 'transformer.resblocks.11.message_ln.weight', 'transformer.resblocks.11.message_ln.bias', 'transformer.resblocks.11.message_attn.in_proj_weight', 'transformer.resblocks.11.message_attn.in_proj_bias', 'transformer.resblocks.11.message_attn.out_proj.weight', 'transformer.resblocks.11.message_attn.out_proj.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'ln_post.weight', 'ln_post.bias'], unexpected_keys=['visual.class_embedding', 'visual.positional_embedding', 'visual.proj', 'visual.conv1.weight', 'visual.ln_pre.weight', 'visual.ln_pre.bias', 'visual.transformer.resblocks.0.attn.in_proj_weight', 'visual.transformer.resblocks.0.attn.in_proj_bias', 'visual.transformer.resblocks.0.attn.out_proj.weight', 'visual.transformer.resblocks.0.attn.out_proj.bias', 'visual.transformer.resblocks.0.ln_1.weight', 'visual.transformer.resblocks.0.ln_1.bias', 'visual.transformer.resblocks.0.mlp.c_fc.weight', 'visual.transformer.resblocks.0.mlp.c_fc.bias', 'visual.transformer.resblocks.0.mlp.c_proj.weight', 'visual.transformer.resblocks.0.mlp.c_proj.bias', 'visual.transformer.resblocks.0.ln_2.weight', 'visual.transformer.resblocks.0.ln_2.bias', 'visual.transformer.resblocks.1.attn.in_proj_weight', 'visual.transformer.resblocks.1.attn.in_proj_bias', 'visual.transformer.resblocks.1.attn.out_proj.weight', 'visual.transformer.resblocks.1.attn.out_proj.bias', 'visual.transformer.resblocks.1.ln_1.weight', 'visual.transformer.resblocks.1.ln_1.bias', 'visual.transformer.resblocks.1.mlp.c_fc.weight', 'visual.transformer.resblocks.1.mlp.c_fc.bias', 'visual.transformer.resblocks.1.mlp.c_proj.weight', 'visual.transformer.resblocks.1.mlp.c_proj.bias', 'visual.transformer.resblocks.1.ln_2.weight', 'visual.transformer.resblocks.1.ln_2.bias', 'visual.transformer.resblocks.2.attn.in_proj_weight', 'visual.transformer.resblocks.2.attn.in_proj_bias', 'visual.transformer.resblocks.2.attn.out_proj.weight', 'visual.transformer.resblocks.2.attn.out_proj.bias', 'visual.transformer.resblocks.2.ln_1.weight', 'visual.transformer.resblocks.2.ln_1.bias', 'visual.transformer.resblocks.2.mlp.c_fc.weight', 'visual.transformer.resblocks.2.mlp.c_fc.bias', 'visual.transformer.resblocks.2.mlp.c_proj.weight', 'visual.transformer.resblocks.2.mlp.c_proj.bias', 'visual.transformer.resblocks.2.ln_2.weight', 'visual.transformer.resblocks.2.ln_2.bias', 'visual.transformer.resblocks.3.attn.in_proj_weight', 'visual.transformer.resblocks.3.attn.in_proj_bias', 'visual.transformer.resblocks.3.attn.out_proj.weight', 'visual.transformer.resblocks.3.attn.out_proj.bias', 'visual.transformer.resblocks.3.ln_1.weight', 'visual.transformer.resblocks.3.ln_1.bias', 'visual.transformer.resblocks.3.mlp.c_fc.weight', 'visual.transformer.resblocks.3.mlp.c_fc.bias', 'visual.transformer.resblocks.3.mlp.c_proj.weight', 'visual.transformer.resblocks.3.mlp.c_proj.bias', 'visual.transformer.resblocks.3.ln_2.weight', 'visual.transformer.resblocks.3.ln_2.bias', 'visual.transformer.resblocks.4.attn.in_proj_weight', 'visual.transformer.resblocks.4.attn.in_proj_bias', 'visual.transformer.resblocks.4.attn.out_proj.weight', 'visual.transformer.resblocks.4.attn.out_proj.bias', 'visual.transformer.resblocks.4.ln_1.weight', 'visual.transformer.resblocks.4.ln_1.bias', 'visual.transformer.resblocks.4.mlp.c_fc.weight', 'visual.transformer.resblocks.4.mlp.c_fc.bias', 'visual.transformer.resblocks.4.mlp.c_proj.weight', 'visual.transformer.resblocks.4.mlp.c_proj.bias', 'visual.transformer.resblocks.4.ln_2.weight', 'visual.transformer.resblocks.4.ln_2.bias', 'visual.transformer.resblocks.5.attn.in_proj_weight', 'visual.transformer.resblocks.5.attn.in_proj_bias', 'visual.transformer.resblocks.5.attn.out_proj.weight', 'visual.transformer.resblocks.5.attn.out_proj.bias', 'visual.transformer.resblocks.5.ln_1.weight', 'visual.transformer.resblocks.5.ln_1.bias', 'visual.transformer.resblocks.5.mlp.c_fc.weight', 'visual.transformer.resblocks.5.mlp.c_fc.bias', 'visual.transformer.resblocks.5.mlp.c_proj.weight', 'visual.transformer.resblocks.5.mlp.c_proj.bias', 'visual.transformer.resblocks.5.ln_2.weight', 'visual.transformer.resblocks.5.ln_2.bias', 'visual.transformer.resblocks.6.attn.in_proj_weight', 'visual.transformer.resblocks.6.attn.in_proj_bias', 'visual.transformer.resblocks.6.attn.out_proj.weight', 'visual.transformer.resblocks.6.attn.out_proj.bias', 'visual.transformer.resblocks.6.ln_1.weight', 'visual.transformer.resblocks.6.ln_1.bias', 'visual.transformer.resblocks.6.mlp.c_fc.weight', 'visual.transformer.resblocks.6.mlp.c_fc.bias', 'visual.transformer.resblocks.6.mlp.c_proj.weight', 'visual.transformer.resblocks.6.mlp.c_proj.bias', 'visual.transformer.resblocks.6.ln_2.weight', 'visual.transformer.resblocks.6.ln_2.bias', 'visual.transformer.resblocks.7.attn.in_proj_weight', 'visual.transformer.resblocks.7.attn.in_proj_bias', 'visual.transformer.resblocks.7.attn.out_proj.weight', 'visual.transformer.resblocks.7.attn.out_proj.bias', 'visual.transformer.resblocks.7.ln_1.weight', 'visual.transformer.resblocks.7.ln_1.bias', 'visual.transformer.resblocks.7.mlp.c_fc.weight', 'visual.transformer.resblocks.7.mlp.c_fc.bias', 'visual.transformer.resblocks.7.mlp.c_proj.weight', 'visual.transformer.resblocks.7.mlp.c_proj.bias', 'visual.transformer.resblocks.7.ln_2.weight', 'visual.transformer.resblocks.7.ln_2.bias', 'visual.transformer.resblocks.8.attn.in_proj_weight', 'visual.transformer.resblocks.8.attn.in_proj_bias', 'visual.transformer.resblocks.8.attn.out_proj.weight', 'visual.transformer.resblocks.8.attn.out_proj.bias', 'visual.transformer.resblocks.8.ln_1.weight', 'visual.transformer.resblocks.8.ln_1.bias', 'visual.transformer.resblocks.8.mlp.c_fc.weight', 'visual.transformer.resblocks.8.mlp.c_fc.bias', 'visual.transformer.resblocks.8.mlp.c_proj.weight', 'visual.transformer.resblocks.8.mlp.c_proj.bias', 'visual.transformer.resblocks.8.ln_2.weight', 'visual.transformer.resblocks.8.ln_2.bias', 'visual.transformer.resblocks.9.attn.in_proj_weight', 'visual.transformer.resblocks.9.attn.in_proj_bias', 'visual.transformer.resblocks.9.attn.out_proj.weight', 'visual.transformer.resblocks.9.attn.out_proj.bias', 'visual.transformer.resblocks.9.ln_1.weight', 'visual.transformer.resblocks.9.ln_1.bias', 'visual.transformer.resblocks.9.mlp.c_fc.weight', 'visual.transformer.resblocks.9.mlp.c_fc.bias', 'visual.transformer.resblocks.9.mlp.c_proj.weight', 'visual.transformer.resblocks.9.mlp.c_proj.bias', 'visual.transformer.resblocks.9.ln_2.weight', 'visual.transformer.resblocks.9.ln_2.bias', 'visual.transformer.resblocks.10.attn.in_proj_weight', 'visual.transformer.resblocks.10.attn.in_proj_bias', 'visual.transformer.resblocks.10.attn.out_proj.weight', 'visual.transformer.resblocks.10.attn.out_proj.bias', 'visual.transformer.resblocks.10.ln_1.weight', 'visual.transformer.resblocks.10.ln_1.bias', 'visual.transformer.resblocks.10.mlp.c_fc.weight', 'visual.transformer.resblocks.10.mlp.c_fc.bias', 'visual.transformer.resblocks.10.mlp.c_proj.weight', 'visual.transformer.resblocks.10.mlp.c_proj.bias', 'visual.transformer.resblocks.10.ln_2.weight', 'visual.transformer.resblocks.10.ln_2.bias', 'visual.transformer.resblocks.11.attn.in_proj_weight', 'visual.transformer.resblocks.11.attn.in_proj_bias', 'visual.transformer.resblocks.11.attn.out_proj.weight', 'visual.transformer.resblocks.11.attn.out_proj.bias', 'visual.transformer.resblocks.11.ln_1.weight', 'visual.transformer.resblocks.11.ln_1.bias', 'visual.transformer.resblocks.11.mlp.c_fc.weight', 'visual.transformer.resblocks.11.mlp.c_fc.bias', 'visual.transformer.resblocks.11.mlp.c_proj.weight', 'visual.transformer.resblocks.11.mlp.c_proj.bias', 'visual.transformer.resblocks.11.ln_2.weight', 'visual.transformer.resblocks.11.ln_2.bias', 'visual.ln_post.weight', 'visual.ln_post.bias'])\n"
     ]
    }
   ],
   "source": [
    "stride_frames = frames[::1]\n",
    "stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "logger = create_logger('./')\n",
    "\n",
    "embed_model, _ = load(None, 'ViT-B/16', \n",
    "                         device=\"cpu\", jit=False, \n",
    "                         T=8, logger=logger\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "torch.Size([2, 64, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stride_frames = frames[::1]\n",
    "stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "print(len(stride_frames))\n",
    "stride_frames = torch.stack(stride_frames, axis=0).unflatten(0, (-1, 64))\n",
    "print(stride_frames.shape)\n",
    "b,t,c,h,w = stride_frames.size()\n",
    "image = stride_frames.reshape(-1,c,h,w)\n",
    "image.shape\n",
    "#with torch.no_grad():\n",
    "#    x=embed_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 512])\n",
      "torch.Size([1, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "for stride in STRIDES:\n",
    "        # Apply stride\n",
    "        stride_frames = x[0][::stride]\n",
    "        stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "        if len(stride_frames) < 64:\n",
    "            continue # Skip this stride if there are not enough frames\n",
    "        stride_frames = stride_frames.unflatten(0, (-1, 64))#torch.stack(stride_frames, axis=0)#.unflatten(0, (-1, 64))#.movedim(1, 2) # Convert to N x C x D x H x W\n",
    "        #stride_frames = stride_frames.to('cpu')\n",
    "        print(stride_frames.shape)\n",
    "        dist = torch.cdist(stride_frames[0], stride_frames[0], p=2)**2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd =dist.numpy()\n",
    "np.fill_diagonal(cd, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dist: np.ndarray, log_scale: bool = False) -> np.ndarray:\n",
    "    \"\"\"Plot the temporal self-similarity matrix into an OpenCV image.\"\"\"\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    if log_scale:\n",
    "        dist = np.log(1 + dist)\n",
    "    dist = -dist # Invert the distance\n",
    "    zmin, zmax = np.nanmin(dist), np.nanmax(dist)\n",
    "    heatmap = (dist - zmin) / (zmax - zmin) # Normalize into [0, 1]\n",
    "    heatmap = np.nan_to_num(heatmap, nan=1)\n",
    "    heatmap = np.clip(heatmap * 255, 0, 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_VIRIDIS)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/gqsn1b5x75x3nstgrhp06xtw0000gp/T/ipykernel_55198/3725310736.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  dist = np.log(1 + dist)\n"
     ]
    }
   ],
   "source": [
    "tsm_img = plot_heatmap(dist.numpy(), log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./tsm.png',tsm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(cd, np.nan)\n",
    "dist = -dist # Invert the distance\n",
    "zmin, zmax = np.nanmin(dist), np.nanmax(dist)\n",
    "heatmap = (dist - zmin) / (zmax - zmin) # Normalize into [0, 1]\n",
    "heatmap = np.nan_to_num(heatmap, nan=1)\n",
    "#heatmap = np.clip(heatmap * 255, 0, 255).astype(np.uint8)\n",
    "#heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_VIRIDIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.09033645, 0.10705061, 0.12384808, 0.12519787,\n",
       "       0.13238014, 0.11348297, 0.09645219, 0.09696878, 0.18128946,\n",
       "       0.13767934, 0.2334483 , 0.2649769 , 0.41192153, 0.47224575,\n",
       "       0.584379  , 0.6739655 , 0.72204167, 0.78493214, 0.7981803 ,\n",
       "       0.7918645 , 0.77593356, 0.76390195, 0.66958284, 0.5973604 ,\n",
       "       0.46881294, 0.38729185, 0.3783099 , 0.20096985, 0.1535103 ,\n",
       "       0.06732324, 0.12869735, 0.16372544, 0.17607358, 0.19958673,\n",
       "       0.20331949, 0.18228932, 0.15489343, 0.08365411, 0.1345298 ,\n",
       "       0.19450416, 0.24129711, 0.26795977, 0.4320185 , 0.5005415 ,\n",
       "       0.5671149 , 0.6029262 , 0.6263227 , 0.7232248 , 0.7322567 ,\n",
       "       0.7386558 , 0.7334233 , 0.73715603, 0.74088883, 0.7367728 ,\n",
       "       0.7395057 , 0.72092515, 0.70969355, 0.6143078 , 0.635238  ,\n",
       "       0.5704644 , 0.51817226, 0.37066105, 0.3526804 ], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted a period length of 33366.7 seconds (~1000000 frames) with a confidence of 0.00 using a stride of 1 frames.\n",
      "Predicted a period length of 33366.7 seconds (~1000000 frames) with a confidence of 0.00 using a stride of 1 frames.\n"
     ]
    }
   ],
   "source": [
    "best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = None, None, None, None, None, None\n",
    "for stride in STRIDES:\n",
    "        # Apply stride\n",
    "        stride_frames = x[0][::stride]\n",
    "        stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "        if len(stride_frames) < 64:\n",
    "            continue # Skip this stride if there are not enough frames\n",
    "        stride_frames = stride_frames.unflatten(0, (-1, 64))\n",
    "        #stride_frames = torch.stack(stride_frames, axis=0)#.unflatten(0, (-1, 64))#.movedim(1, 2) # Convert to N x C x D x H x W\n",
    "        #stride_frames = stride_frames.to('cpu')\n",
    "        #print(stride_frames.shape)\n",
    "        raw_period_length, raw_periodicity_score, embeddings = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for i in range(stride_frames.shape[0]):  # Process each batch separately to avoid OOM\n",
    "                batch_period_length, batch_periodicity, batch_embeddings = model(stride_frames)\n",
    "                raw_period_length.append(batch_period_length[0].cpu())\n",
    "                raw_periodicity_score.append(batch_periodicity[0].cpu())\n",
    "                embeddings.append(batch_embeddings[0].cpu()) \n",
    "        # Post-process results\n",
    "        raw_period_length, raw_periodicity_score, embeddings = torch.cat(raw_period_length), torch.cat(raw_periodicity_score), torch.cat(embeddings)\n",
    "        confidence, period_length, period_count, periodicity_score = model.get_counts(raw_period_length, raw_periodicity_score, stride)\n",
    "        if best_confidence is None or confidence > best_confidence:\n",
    "            best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = stride, confidence, period_length, period_count, periodicity_score, embeddings\n",
    "        if best_stride is None:\n",
    "            raise RuntimeError('The stride values used are too large and nove 64 video chunk could be sampled. Try different values for --strides.')\n",
    "        print(f'Predicted a period length of {best_period_length/fps:.1f} seconds (~{int(best_period_length)} frames) with a confidence of {best_confidence:.2f} using a stride of {best_stride} frames.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.6993,  3.0649, -0.2384,  0.0580, -1.2835,  0.5521,  0.5216,  1.0147,\n",
       "        -0.8328,  0.8525,  2.1904,  0.4364, -1.1787, -0.1614, -0.7137,  1.3902,\n",
       "        -1.3939, -0.1937, -2.3317, -0.1535, -1.8956, -1.9995, -1.9873, -1.2603,\n",
       "        -1.0427, -0.2675, -1.5361,  0.1526, -0.8788, -0.5716, -1.6364,  0.5365])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_period_length[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_length_confidence, period_length = torch.max(torch.softmax(raw_period_length, dim=-1), dim=-1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_length < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_frames = plots.plot_repetitions(raw_frames[:len(best_period_count)], best_period_count.tolist(), best_periodicity_score.tolist() )\n",
    "video = cv2.VideoWriter(os.path.join('./videos', 'repetitions.mp4'), cv2.VideoWriter_fourcc(*'mp4v'), fps, rep_frames[0].shape[:2][::-1])\n",
    "for frame in rep_frames:\n",
    "        video.write(frame)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
