{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('./xclip'))\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclip\n",
    "import xclip.models.xclip as xclip\n",
    "from xclip.utils.logger import create_logger\n",
    "logger = create_logger('./')\n",
    "import numpy as np\n",
    "import torch\n",
    "from xclip.utils.config import  get_config  \n",
    "from xclip.models.cct import load\n",
    "import xclip.datasets.build as build\n",
    "import cv2\n",
    "import timm\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from ./xclip/configs/countix/countix.yaml\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = './xclip/configs/countix/countix.yaml'\n",
    "        self.opts = None\n",
    "        self.auto_resume = False\n",
    "        self.batch_size=4\n",
    "        self.pretrained=None\n",
    "        self.resume=False\n",
    "        self.accumulation_steps=None\n",
    "        self.output=None\n",
    "        self.only_test=False\n",
    "        self.local_rank=None\n",
    "args = Args()\n",
    "config=get_config(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-21 14:50:32 root]\u001b[0m\u001b[33m(cct.py 289)\u001b[0m: INFO load pretrained CLIP: _IncompatibleKeys(missing_keys=['class_embedding', 'positional_embedding', 'proj', 'conv1.weight', 'ln_pre.weight', 'ln_pre.bias', 'transformer.resblocks.0.message_fc.weight', 'transformer.resblocks.0.message_fc.bias', 'transformer.resblocks.0.message_ln.weight', 'transformer.resblocks.0.message_ln.bias', 'transformer.resblocks.0.message_attn.in_proj_weight', 'transformer.resblocks.0.message_attn.in_proj_bias', 'transformer.resblocks.0.message_attn.out_proj.weight', 'transformer.resblocks.0.message_attn.out_proj.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.message_fc.weight', 'transformer.resblocks.1.message_fc.bias', 'transformer.resblocks.1.message_ln.weight', 'transformer.resblocks.1.message_ln.bias', 'transformer.resblocks.1.message_attn.in_proj_weight', 'transformer.resblocks.1.message_attn.in_proj_bias', 'transformer.resblocks.1.message_attn.out_proj.weight', 'transformer.resblocks.1.message_attn.out_proj.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.message_fc.weight', 'transformer.resblocks.2.message_fc.bias', 'transformer.resblocks.2.message_ln.weight', 'transformer.resblocks.2.message_ln.bias', 'transformer.resblocks.2.message_attn.in_proj_weight', 'transformer.resblocks.2.message_attn.in_proj_bias', 'transformer.resblocks.2.message_attn.out_proj.weight', 'transformer.resblocks.2.message_attn.out_proj.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.message_fc.weight', 'transformer.resblocks.3.message_fc.bias', 'transformer.resblocks.3.message_ln.weight', 'transformer.resblocks.3.message_ln.bias', 'transformer.resblocks.3.message_attn.in_proj_weight', 'transformer.resblocks.3.message_attn.in_proj_bias', 'transformer.resblocks.3.message_attn.out_proj.weight', 'transformer.resblocks.3.message_attn.out_proj.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.message_fc.weight', 'transformer.resblocks.4.message_fc.bias', 'transformer.resblocks.4.message_ln.weight', 'transformer.resblocks.4.message_ln.bias', 'transformer.resblocks.4.message_attn.in_proj_weight', 'transformer.resblocks.4.message_attn.in_proj_bias', 'transformer.resblocks.4.message_attn.out_proj.weight', 'transformer.resblocks.4.message_attn.out_proj.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.message_fc.weight', 'transformer.resblocks.5.message_fc.bias', 'transformer.resblocks.5.message_ln.weight', 'transformer.resblocks.5.message_ln.bias', 'transformer.resblocks.5.message_attn.in_proj_weight', 'transformer.resblocks.5.message_attn.in_proj_bias', 'transformer.resblocks.5.message_attn.out_proj.weight', 'transformer.resblocks.5.message_attn.out_proj.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.message_fc.weight', 'transformer.resblocks.6.message_fc.bias', 'transformer.resblocks.6.message_ln.weight', 'transformer.resblocks.6.message_ln.bias', 'transformer.resblocks.6.message_attn.in_proj_weight', 'transformer.resblocks.6.message_attn.in_proj_bias', 'transformer.resblocks.6.message_attn.out_proj.weight', 'transformer.resblocks.6.message_attn.out_proj.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.message_fc.weight', 'transformer.resblocks.7.message_fc.bias', 'transformer.resblocks.7.message_ln.weight', 'transformer.resblocks.7.message_ln.bias', 'transformer.resblocks.7.message_attn.in_proj_weight', 'transformer.resblocks.7.message_attn.in_proj_bias', 'transformer.resblocks.7.message_attn.out_proj.weight', 'transformer.resblocks.7.message_attn.out_proj.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.message_fc.weight', 'transformer.resblocks.8.message_fc.bias', 'transformer.resblocks.8.message_ln.weight', 'transformer.resblocks.8.message_ln.bias', 'transformer.resblocks.8.message_attn.in_proj_weight', 'transformer.resblocks.8.message_attn.in_proj_bias', 'transformer.resblocks.8.message_attn.out_proj.weight', 'transformer.resblocks.8.message_attn.out_proj.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.message_fc.weight', 'transformer.resblocks.9.message_fc.bias', 'transformer.resblocks.9.message_ln.weight', 'transformer.resblocks.9.message_ln.bias', 'transformer.resblocks.9.message_attn.in_proj_weight', 'transformer.resblocks.9.message_attn.in_proj_bias', 'transformer.resblocks.9.message_attn.out_proj.weight', 'transformer.resblocks.9.message_attn.out_proj.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.message_fc.weight', 'transformer.resblocks.10.message_fc.bias', 'transformer.resblocks.10.message_ln.weight', 'transformer.resblocks.10.message_ln.bias', 'transformer.resblocks.10.message_attn.in_proj_weight', 'transformer.resblocks.10.message_attn.in_proj_bias', 'transformer.resblocks.10.message_attn.out_proj.weight', 'transformer.resblocks.10.message_attn.out_proj.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.message_fc.weight', 'transformer.resblocks.11.message_fc.bias', 'transformer.resblocks.11.message_ln.weight', 'transformer.resblocks.11.message_ln.bias', 'transformer.resblocks.11.message_attn.in_proj_weight', 'transformer.resblocks.11.message_attn.in_proj_bias', 'transformer.resblocks.11.message_attn.out_proj.weight', 'transformer.resblocks.11.message_attn.out_proj.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'ln_post.weight', 'ln_post.bias', 'mit.positional_embedding', 'mit.resblocks.0.attn.in_proj_weight', 'mit.resblocks.0.attn.in_proj_bias', 'mit.resblocks.0.attn.out_proj.weight', 'mit.resblocks.0.attn.out_proj.bias', 'mit.resblocks.0.ln_1.weight', 'mit.resblocks.0.ln_1.bias', 'mit.resblocks.0.mlp.c_fc.weight', 'mit.resblocks.0.mlp.c_fc.bias', 'mit.resblocks.0.mlp.c_proj.weight', 'mit.resblocks.0.mlp.c_proj.bias', 'mit.resblocks.0.ln_2.weight', 'mit.resblocks.0.ln_2.bias', 'mit.resblocks.1.attn.in_proj_weight', 'mit.resblocks.1.attn.in_proj_bias', 'mit.resblocks.1.attn.out_proj.weight', 'mit.resblocks.1.attn.out_proj.bias', 'mit.resblocks.1.ln_1.weight', 'mit.resblocks.1.ln_1.bias', 'mit.resblocks.1.mlp.c_fc.weight', 'mit.resblocks.1.mlp.c_fc.bias', 'mit.resblocks.1.mlp.c_proj.weight', 'mit.resblocks.1.mlp.c_proj.bias', 'mit.resblocks.1.ln_2.weight', 'mit.resblocks.1.ln_2.bias', 'mit.resblocks.2.attn.in_proj_weight', 'mit.resblocks.2.attn.in_proj_bias', 'mit.resblocks.2.attn.out_proj.weight', 'mit.resblocks.2.attn.out_proj.bias', 'mit.resblocks.2.ln_1.weight', 'mit.resblocks.2.ln_1.bias', 'mit.resblocks.2.mlp.c_fc.weight', 'mit.resblocks.2.mlp.c_fc.bias', 'mit.resblocks.2.mlp.c_proj.weight', 'mit.resblocks.2.mlp.c_proj.bias', 'mit.resblocks.2.ln_2.weight', 'mit.resblocks.2.ln_2.bias', 'mit.resblocks.3.attn.in_proj_weight', 'mit.resblocks.3.attn.in_proj_bias', 'mit.resblocks.3.attn.out_proj.weight', 'mit.resblocks.3.attn.out_proj.bias', 'mit.resblocks.3.ln_1.weight', 'mit.resblocks.3.ln_1.bias', 'mit.resblocks.3.mlp.c_fc.weight', 'mit.resblocks.3.mlp.c_fc.bias', 'mit.resblocks.3.mlp.c_proj.weight', 'mit.resblocks.3.mlp.c_proj.bias', 'mit.resblocks.3.ln_2.weight', 'mit.resblocks.3.ln_2.bias'], unexpected_keys=['visual.class_embedding', 'visual.positional_embedding', 'visual.proj', 'visual.conv1.weight', 'visual.ln_pre.weight', 'visual.ln_pre.bias', 'visual.transformer.resblocks.0.attn.in_proj_weight', 'visual.transformer.resblocks.0.attn.in_proj_bias', 'visual.transformer.resblocks.0.attn.out_proj.weight', 'visual.transformer.resblocks.0.attn.out_proj.bias', 'visual.transformer.resblocks.0.ln_1.weight', 'visual.transformer.resblocks.0.ln_1.bias', 'visual.transformer.resblocks.0.mlp.c_fc.weight', 'visual.transformer.resblocks.0.mlp.c_fc.bias', 'visual.transformer.resblocks.0.mlp.c_proj.weight', 'visual.transformer.resblocks.0.mlp.c_proj.bias', 'visual.transformer.resblocks.0.ln_2.weight', 'visual.transformer.resblocks.0.ln_2.bias', 'visual.transformer.resblocks.1.attn.in_proj_weight', 'visual.transformer.resblocks.1.attn.in_proj_bias', 'visual.transformer.resblocks.1.attn.out_proj.weight', 'visual.transformer.resblocks.1.attn.out_proj.bias', 'visual.transformer.resblocks.1.ln_1.weight', 'visual.transformer.resblocks.1.ln_1.bias', 'visual.transformer.resblocks.1.mlp.c_fc.weight', 'visual.transformer.resblocks.1.mlp.c_fc.bias', 'visual.transformer.resblocks.1.mlp.c_proj.weight', 'visual.transformer.resblocks.1.mlp.c_proj.bias', 'visual.transformer.resblocks.1.ln_2.weight', 'visual.transformer.resblocks.1.ln_2.bias', 'visual.transformer.resblocks.2.attn.in_proj_weight', 'visual.transformer.resblocks.2.attn.in_proj_bias', 'visual.transformer.resblocks.2.attn.out_proj.weight', 'visual.transformer.resblocks.2.attn.out_proj.bias', 'visual.transformer.resblocks.2.ln_1.weight', 'visual.transformer.resblocks.2.ln_1.bias', 'visual.transformer.resblocks.2.mlp.c_fc.weight', 'visual.transformer.resblocks.2.mlp.c_fc.bias', 'visual.transformer.resblocks.2.mlp.c_proj.weight', 'visual.transformer.resblocks.2.mlp.c_proj.bias', 'visual.transformer.resblocks.2.ln_2.weight', 'visual.transformer.resblocks.2.ln_2.bias', 'visual.transformer.resblocks.3.attn.in_proj_weight', 'visual.transformer.resblocks.3.attn.in_proj_bias', 'visual.transformer.resblocks.3.attn.out_proj.weight', 'visual.transformer.resblocks.3.attn.out_proj.bias', 'visual.transformer.resblocks.3.ln_1.weight', 'visual.transformer.resblocks.3.ln_1.bias', 'visual.transformer.resblocks.3.mlp.c_fc.weight', 'visual.transformer.resblocks.3.mlp.c_fc.bias', 'visual.transformer.resblocks.3.mlp.c_proj.weight', 'visual.transformer.resblocks.3.mlp.c_proj.bias', 'visual.transformer.resblocks.3.ln_2.weight', 'visual.transformer.resblocks.3.ln_2.bias', 'visual.transformer.resblocks.4.attn.in_proj_weight', 'visual.transformer.resblocks.4.attn.in_proj_bias', 'visual.transformer.resblocks.4.attn.out_proj.weight', 'visual.transformer.resblocks.4.attn.out_proj.bias', 'visual.transformer.resblocks.4.ln_1.weight', 'visual.transformer.resblocks.4.ln_1.bias', 'visual.transformer.resblocks.4.mlp.c_fc.weight', 'visual.transformer.resblocks.4.mlp.c_fc.bias', 'visual.transformer.resblocks.4.mlp.c_proj.weight', 'visual.transformer.resblocks.4.mlp.c_proj.bias', 'visual.transformer.resblocks.4.ln_2.weight', 'visual.transformer.resblocks.4.ln_2.bias', 'visual.transformer.resblocks.5.attn.in_proj_weight', 'visual.transformer.resblocks.5.attn.in_proj_bias', 'visual.transformer.resblocks.5.attn.out_proj.weight', 'visual.transformer.resblocks.5.attn.out_proj.bias', 'visual.transformer.resblocks.5.ln_1.weight', 'visual.transformer.resblocks.5.ln_1.bias', 'visual.transformer.resblocks.5.mlp.c_fc.weight', 'visual.transformer.resblocks.5.mlp.c_fc.bias', 'visual.transformer.resblocks.5.mlp.c_proj.weight', 'visual.transformer.resblocks.5.mlp.c_proj.bias', 'visual.transformer.resblocks.5.ln_2.weight', 'visual.transformer.resblocks.5.ln_2.bias', 'visual.transformer.resblocks.6.attn.in_proj_weight', 'visual.transformer.resblocks.6.attn.in_proj_bias', 'visual.transformer.resblocks.6.attn.out_proj.weight', 'visual.transformer.resblocks.6.attn.out_proj.bias', 'visual.transformer.resblocks.6.ln_1.weight', 'visual.transformer.resblocks.6.ln_1.bias', 'visual.transformer.resblocks.6.mlp.c_fc.weight', 'visual.transformer.resblocks.6.mlp.c_fc.bias', 'visual.transformer.resblocks.6.mlp.c_proj.weight', 'visual.transformer.resblocks.6.mlp.c_proj.bias', 'visual.transformer.resblocks.6.ln_2.weight', 'visual.transformer.resblocks.6.ln_2.bias', 'visual.transformer.resblocks.7.attn.in_proj_weight', 'visual.transformer.resblocks.7.attn.in_proj_bias', 'visual.transformer.resblocks.7.attn.out_proj.weight', 'visual.transformer.resblocks.7.attn.out_proj.bias', 'visual.transformer.resblocks.7.ln_1.weight', 'visual.transformer.resblocks.7.ln_1.bias', 'visual.transformer.resblocks.7.mlp.c_fc.weight', 'visual.transformer.resblocks.7.mlp.c_fc.bias', 'visual.transformer.resblocks.7.mlp.c_proj.weight', 'visual.transformer.resblocks.7.mlp.c_proj.bias', 'visual.transformer.resblocks.7.ln_2.weight', 'visual.transformer.resblocks.7.ln_2.bias', 'visual.transformer.resblocks.8.attn.in_proj_weight', 'visual.transformer.resblocks.8.attn.in_proj_bias', 'visual.transformer.resblocks.8.attn.out_proj.weight', 'visual.transformer.resblocks.8.attn.out_proj.bias', 'visual.transformer.resblocks.8.ln_1.weight', 'visual.transformer.resblocks.8.ln_1.bias', 'visual.transformer.resblocks.8.mlp.c_fc.weight', 'visual.transformer.resblocks.8.mlp.c_fc.bias', 'visual.transformer.resblocks.8.mlp.c_proj.weight', 'visual.transformer.resblocks.8.mlp.c_proj.bias', 'visual.transformer.resblocks.8.ln_2.weight', 'visual.transformer.resblocks.8.ln_2.bias', 'visual.transformer.resblocks.9.attn.in_proj_weight', 'visual.transformer.resblocks.9.attn.in_proj_bias', 'visual.transformer.resblocks.9.attn.out_proj.weight', 'visual.transformer.resblocks.9.attn.out_proj.bias', 'visual.transformer.resblocks.9.ln_1.weight', 'visual.transformer.resblocks.9.ln_1.bias', 'visual.transformer.resblocks.9.mlp.c_fc.weight', 'visual.transformer.resblocks.9.mlp.c_fc.bias', 'visual.transformer.resblocks.9.mlp.c_proj.weight', 'visual.transformer.resblocks.9.mlp.c_proj.bias', 'visual.transformer.resblocks.9.ln_2.weight', 'visual.transformer.resblocks.9.ln_2.bias', 'visual.transformer.resblocks.10.attn.in_proj_weight', 'visual.transformer.resblocks.10.attn.in_proj_bias', 'visual.transformer.resblocks.10.attn.out_proj.weight', 'visual.transformer.resblocks.10.attn.out_proj.bias', 'visual.transformer.resblocks.10.ln_1.weight', 'visual.transformer.resblocks.10.ln_1.bias', 'visual.transformer.resblocks.10.mlp.c_fc.weight', 'visual.transformer.resblocks.10.mlp.c_fc.bias', 'visual.transformer.resblocks.10.mlp.c_proj.weight', 'visual.transformer.resblocks.10.mlp.c_proj.bias', 'visual.transformer.resblocks.10.ln_2.weight', 'visual.transformer.resblocks.10.ln_2.bias', 'visual.transformer.resblocks.11.attn.in_proj_weight', 'visual.transformer.resblocks.11.attn.in_proj_bias', 'visual.transformer.resblocks.11.attn.out_proj.weight', 'visual.transformer.resblocks.11.attn.out_proj.bias', 'visual.transformer.resblocks.11.ln_1.weight', 'visual.transformer.resblocks.11.ln_1.bias', 'visual.transformer.resblocks.11.mlp.c_fc.weight', 'visual.transformer.resblocks.11.mlp.c_fc.bias', 'visual.transformer.resblocks.11.mlp.c_proj.weight', 'visual.transformer.resblocks.11.mlp.c_proj.bias', 'visual.transformer.resblocks.11.ln_2.weight', 'visual.transformer.resblocks.11.ln_2.bias', 'visual.ln_post.weight', 'visual.ln_post.bias'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_model, _ = load(None, 'ViT-B/16', \n",
    "                         device=\"cpu\", jit=False, \n",
    "                         T=384, logger=logger\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['class_embedding', 'positional_embedding', 'proj', 'conv1.weight', 'ln_pre.weight', 'ln_pre.bias', 'transformer.resblocks.0.message_fc.weight', 'transformer.resblocks.0.message_fc.bias', 'transformer.resblocks.0.message_ln.weight', 'transformer.resblocks.0.message_ln.bias', 'transformer.resblocks.0.message_attn.in_proj_weight', 'transformer.resblocks.0.message_attn.in_proj_bias', 'transformer.resblocks.0.message_attn.out_proj.weight', 'transformer.resblocks.0.message_attn.out_proj.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.message_fc.weight', 'transformer.resblocks.1.message_fc.bias', 'transformer.resblocks.1.message_ln.weight', 'transformer.resblocks.1.message_ln.bias', 'transformer.resblocks.1.message_attn.in_proj_weight', 'transformer.resblocks.1.message_attn.in_proj_bias', 'transformer.resblocks.1.message_attn.out_proj.weight', 'transformer.resblocks.1.message_attn.out_proj.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.message_fc.weight', 'transformer.resblocks.2.message_fc.bias', 'transformer.resblocks.2.message_ln.weight', 'transformer.resblocks.2.message_ln.bias', 'transformer.resblocks.2.message_attn.in_proj_weight', 'transformer.resblocks.2.message_attn.in_proj_bias', 'transformer.resblocks.2.message_attn.out_proj.weight', 'transformer.resblocks.2.message_attn.out_proj.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.message_fc.weight', 'transformer.resblocks.3.message_fc.bias', 'transformer.resblocks.3.message_ln.weight', 'transformer.resblocks.3.message_ln.bias', 'transformer.resblocks.3.message_attn.in_proj_weight', 'transformer.resblocks.3.message_attn.in_proj_bias', 'transformer.resblocks.3.message_attn.out_proj.weight', 'transformer.resblocks.3.message_attn.out_proj.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.message_fc.weight', 'transformer.resblocks.4.message_fc.bias', 'transformer.resblocks.4.message_ln.weight', 'transformer.resblocks.4.message_ln.bias', 'transformer.resblocks.4.message_attn.in_proj_weight', 'transformer.resblocks.4.message_attn.in_proj_bias', 'transformer.resblocks.4.message_attn.out_proj.weight', 'transformer.resblocks.4.message_attn.out_proj.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.message_fc.weight', 'transformer.resblocks.5.message_fc.bias', 'transformer.resblocks.5.message_ln.weight', 'transformer.resblocks.5.message_ln.bias', 'transformer.resblocks.5.message_attn.in_proj_weight', 'transformer.resblocks.5.message_attn.in_proj_bias', 'transformer.resblocks.5.message_attn.out_proj.weight', 'transformer.resblocks.5.message_attn.out_proj.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.message_fc.weight', 'transformer.resblocks.6.message_fc.bias', 'transformer.resblocks.6.message_ln.weight', 'transformer.resblocks.6.message_ln.bias', 'transformer.resblocks.6.message_attn.in_proj_weight', 'transformer.resblocks.6.message_attn.in_proj_bias', 'transformer.resblocks.6.message_attn.out_proj.weight', 'transformer.resblocks.6.message_attn.out_proj.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.message_fc.weight', 'transformer.resblocks.7.message_fc.bias', 'transformer.resblocks.7.message_ln.weight', 'transformer.resblocks.7.message_ln.bias', 'transformer.resblocks.7.message_attn.in_proj_weight', 'transformer.resblocks.7.message_attn.in_proj_bias', 'transformer.resblocks.7.message_attn.out_proj.weight', 'transformer.resblocks.7.message_attn.out_proj.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.message_fc.weight', 'transformer.resblocks.8.message_fc.bias', 'transformer.resblocks.8.message_ln.weight', 'transformer.resblocks.8.message_ln.bias', 'transformer.resblocks.8.message_attn.in_proj_weight', 'transformer.resblocks.8.message_attn.in_proj_bias', 'transformer.resblocks.8.message_attn.out_proj.weight', 'transformer.resblocks.8.message_attn.out_proj.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.message_fc.weight', 'transformer.resblocks.9.message_fc.bias', 'transformer.resblocks.9.message_ln.weight', 'transformer.resblocks.9.message_ln.bias', 'transformer.resblocks.9.message_attn.in_proj_weight', 'transformer.resblocks.9.message_attn.in_proj_bias', 'transformer.resblocks.9.message_attn.out_proj.weight', 'transformer.resblocks.9.message_attn.out_proj.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.message_fc.weight', 'transformer.resblocks.10.message_fc.bias', 'transformer.resblocks.10.message_ln.weight', 'transformer.resblocks.10.message_ln.bias', 'transformer.resblocks.10.message_attn.in_proj_weight', 'transformer.resblocks.10.message_attn.in_proj_bias', 'transformer.resblocks.10.message_attn.out_proj.weight', 'transformer.resblocks.10.message_attn.out_proj.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.message_fc.weight', 'transformer.resblocks.11.message_fc.bias', 'transformer.resblocks.11.message_ln.weight', 'transformer.resblocks.11.message_ln.bias', 'transformer.resblocks.11.message_attn.in_proj_weight', 'transformer.resblocks.11.message_attn.in_proj_bias', 'transformer.resblocks.11.message_attn.out_proj.weight', 'transformer.resblocks.11.message_attn.out_proj.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'ln_post.weight', 'ln_post.bias', 'mit.positional_embedding', 'mit.resblocks.0.attn.in_proj_weight', 'mit.resblocks.0.attn.in_proj_bias', 'mit.resblocks.0.attn.out_proj.weight', 'mit.resblocks.0.attn.out_proj.bias', 'mit.resblocks.0.ln_1.weight', 'mit.resblocks.0.ln_1.bias', 'mit.resblocks.0.mlp.c_fc.weight', 'mit.resblocks.0.mlp.c_fc.bias', 'mit.resblocks.0.mlp.c_proj.weight', 'mit.resblocks.0.mlp.c_proj.bias', 'mit.resblocks.0.ln_2.weight', 'mit.resblocks.0.ln_2.bias', 'mit.resblocks.1.attn.in_proj_weight', 'mit.resblocks.1.attn.in_proj_bias', 'mit.resblocks.1.attn.out_proj.weight', 'mit.resblocks.1.attn.out_proj.bias', 'mit.resblocks.1.ln_1.weight', 'mit.resblocks.1.ln_1.bias', 'mit.resblocks.1.mlp.c_fc.weight', 'mit.resblocks.1.mlp.c_fc.bias', 'mit.resblocks.1.mlp.c_proj.weight', 'mit.resblocks.1.mlp.c_proj.bias', 'mit.resblocks.1.ln_2.weight', 'mit.resblocks.1.ln_2.bias', 'mit.resblocks.2.attn.in_proj_weight', 'mit.resblocks.2.attn.in_proj_bias', 'mit.resblocks.2.attn.out_proj.weight', 'mit.resblocks.2.attn.out_proj.bias', 'mit.resblocks.2.ln_1.weight', 'mit.resblocks.2.ln_1.bias', 'mit.resblocks.2.mlp.c_fc.weight', 'mit.resblocks.2.mlp.c_fc.bias', 'mit.resblocks.2.mlp.c_proj.weight', 'mit.resblocks.2.mlp.c_proj.bias', 'mit.resblocks.2.ln_2.weight', 'mit.resblocks.2.ln_2.bias', 'mit.resblocks.3.attn.in_proj_weight', 'mit.resblocks.3.attn.in_proj_bias', 'mit.resblocks.3.attn.out_proj.weight', 'mit.resblocks.3.attn.out_proj.bias', 'mit.resblocks.3.ln_1.weight', 'mit.resblocks.3.ln_1.bias', 'mit.resblocks.3.mlp.c_fc.weight', 'mit.resblocks.3.mlp.c_fc.bias', 'mit.resblocks.3.mlp.c_proj.weight', 'mit.resblocks.3.mlp.c_proj.bias', 'mit.resblocks.3.ln_2.weight', 'mit.resblocks.3.ln_2.bias'])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,train_loader = build.build_counitxdataloader(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[80432]: Class AVFFrameReceiver is implemented in both /Users/kanantharaman/anaconda3/lib/python3.11/site-packages/av/.dylibs/libavdevice.60.3.100.dylib (0x1445a10f8) and /Users/kanantharaman/anaconda3/lib/python3.11/site-packages/decord/.dylibs/libavdevice.58.5.100.dylib (0x15c7c5010). One of the two will be used. Which one is undefined.\n",
      "objc[80432]: Class AVFAudioReceiver is implemented in both /Users/kanantharaman/anaconda3/lib/python3.11/site-packages/av/.dylibs/libavdevice.60.3.100.dylib (0x1445a1148) and /Users/kanantharaman/anaconda3/lib/python3.11/site-packages/decord/.dylibs/libavdevice.58.5.100.dylib (0x15c7c5060). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/22 20:55:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "11/22 20:55:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "dict_keys(['imgs', 'label', 'start', 'end', 'count'])\n",
      "torch.Size([4, 384, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch_data in enumerate(train_loader):\n",
    "     print(batch_data.keys())\n",
    "     images = batch_data[\"imgs\"]\n",
    "     #b,t,c,h,w = images.size()\n",
    "     #images = images.reshape(-1,c,h,w)\n",
    "     print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use MP4V codec\n",
    "video = cv2.VideoWriter('video.mp4',fourcc, 1, (w,h))\n",
    "for image in batch_data[\"imgs\"][0]:\n",
    "    video.write(np.uint8(np.transpose(image.numpy(), (1, 2, 0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 3, 224, 224])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m    x\u001b[38;5;241m=\u001b[39membed_model(images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_model' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   x=embed_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2765e+00, -1.2453e+00, -1.3994e+00,  ...,  7.8184e-01,\n",
       "           2.3767e+00,  5.7451e+00],\n",
       "         [-2.2415e+00, -1.2316e+00, -1.3751e+00,  ...,  7.8824e-01,\n",
       "           2.4570e+00,  5.7667e+00],\n",
       "         [-2.2498e+00, -1.2333e+00, -1.3281e+00,  ...,  7.7489e-01,\n",
       "           2.3990e+00,  5.7160e+00],\n",
       "         ...,\n",
       "         [-1.9052e+00, -1.4399e+00, -2.6906e+00,  ...,  1.9424e-01,\n",
       "           2.7023e+00,  4.7429e+00],\n",
       "         [-1.8936e+00, -1.4266e+00, -2.7028e+00,  ...,  1.6222e-01,\n",
       "           2.6784e+00,  4.7573e+00],\n",
       "         [-1.8743e+00, -1.4172e+00, -2.6789e+00,  ...,  2.1330e-01,\n",
       "           2.7168e+00,  4.7493e+00]],\n",
       "\n",
       "        [[-2.0981e+00, -1.5501e+00, -1.4070e+00,  ...,  1.8525e+00,\n",
       "           2.3132e+00,  5.6870e+00],\n",
       "         [-2.0845e+00, -1.5436e+00, -1.3920e+00,  ...,  1.8785e+00,\n",
       "           2.4019e+00,  5.6975e+00],\n",
       "         [-2.0529e+00, -1.4832e+00, -1.2407e+00,  ...,  1.6547e+00,\n",
       "           2.4239e+00,  5.5727e+00],\n",
       "         ...,\n",
       "         [-1.9533e+00, -1.0859e+00, -7.6560e-01,  ...,  1.8427e+00,\n",
       "           2.3537e+00,  5.4428e+00],\n",
       "         [-1.9036e+00, -1.0862e+00, -7.8773e-01,  ...,  1.8267e+00,\n",
       "           2.3298e+00,  5.4361e+00],\n",
       "         [-1.9333e+00, -1.2235e+00, -8.5945e-01,  ...,  1.9590e+00,\n",
       "           2.4834e+00,  5.4941e+00]],\n",
       "\n",
       "        [[-9.8847e-01, -2.8952e-01,  1.2902e+00,  ...,  1.0537e+00,\n",
       "           8.5312e-01,  4.7071e+00],\n",
       "         [-9.5944e-01, -2.9298e-01,  1.2924e+00,  ...,  1.0762e+00,\n",
       "           9.5202e-01,  4.7351e+00],\n",
       "         [-9.4693e-01, -2.9356e-01,  1.3214e+00,  ...,  1.0914e+00,\n",
       "           9.0629e-01,  4.7213e+00],\n",
       "         ...,\n",
       "         [-1.8618e+00, -1.4376e+00, -2.6250e+00,  ..., -1.6901e-01,\n",
       "           3.1114e+00,  4.2777e+00],\n",
       "         [-1.8497e+00, -1.4253e+00, -2.6399e+00,  ..., -2.0195e-01,\n",
       "           3.0912e+00,  4.2908e+00],\n",
       "         [-1.8314e+00, -1.4160e+00, -2.6130e+00,  ..., -1.4984e-01,\n",
       "           3.1270e+00,  4.2818e+00]],\n",
       "\n",
       "        [[-1.7851e+00, -5.2928e-01,  4.4458e-01,  ...,  8.4429e-01,\n",
       "           7.0457e-01,  4.9634e+00],\n",
       "         [-1.7519e+00, -4.9401e-01,  5.0136e-01,  ...,  8.1541e-01,\n",
       "           7.7993e-01,  5.0015e+00],\n",
       "         [-1.6883e+00, -4.4227e-01,  5.4705e-01,  ...,  7.5836e-01,\n",
       "           7.4869e-01,  4.9553e+00],\n",
       "         ...,\n",
       "         [-1.8646e+00, -1.4465e+00, -2.6701e+00,  ...,  2.1068e-03,\n",
       "           2.8552e+00,  4.5635e+00],\n",
       "         [-1.8528e+00, -1.4335e+00, -2.6836e+00,  ..., -3.0210e-02,\n",
       "           2.8328e+00,  4.5772e+00],\n",
       "         [-1.8344e+00, -1.4247e+00, -2.6579e+00,  ...,  2.1021e-02,\n",
       "           2.8701e+00,  4.5686e+00]]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_features = x[0]#.view(b, t, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 208, 512])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].mean(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 384, 512]), torch.Size([4, 384, 512]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_features.shape,cls_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dist: np.ndarray, log_scale: bool = False) -> np.ndarray:\n",
    "    \"\"\"Plot the temporal self-similarity matrix into an OpenCV image.\"\"\"\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    if log_scale:\n",
    "        dist = np.log(1 + dist)\n",
    "    dist = -dist # Invert the distance\n",
    "    zmin, zmax = np.nanmin(dist), np.nanmax(dist)\n",
    "    heatmap = (dist - zmin) / (zmax - zmin) # Normalize into [0, 1]\n",
    "    heatmap = np.nan_to_num(heatmap, nan=1)\n",
    "    heatmap = np.clip(heatmap * 255, 0, 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_VIRIDIS)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-15 21:55:56 matplotlib]\u001b[0m\u001b[33m(__init__.py 305)\u001b[0m: DEBUG matplotlib data path: /Users/kanantharaman/anaconda3/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "\u001b[32m[2024-11-15 21:55:56 matplotlib]\u001b[0m\u001b[33m(__init__.py 305)\u001b[0m: DEBUG CONFIGDIR=/Users/kanantharaman/.matplotlib\n",
      "\u001b[32m[2024-11-15 21:55:56 matplotlib]\u001b[0m\u001b[33m(__init__.py 1479)\u001b[0m: DEBUG interactive is False\n",
      "\u001b[32m[2024-11-15 21:55:56 matplotlib]\u001b[0m\u001b[33m(__init__.py 1480)\u001b[0m: DEBUG platform is darwin\n",
      "\u001b[32m[2024-11-15 21:55:56 matplotlib]\u001b[0m\u001b[33m(__init__.py 305)\u001b[0m: DEBUG CACHEDIR=/Users/kanantharaman/.matplotlib\n",
      "\u001b[32m[2024-11-15 21:55:56 matplotlib.font_manager]\u001b[0m\u001b[33m(font_manager.py 1543)\u001b[0m: DEBUG Using fontManager instance from /Users/kanantharaman/.matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 208, 512])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/gqsn1b5x75x3nstgrhp06xtw0000gp/T/ipykernel_2231/3725310736.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  dist = np.log(1 + dist)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx in range(img_features.shape[0]):\n",
    "    dist = torch.cdist(img_features[0], img_features[0], p=2)**2\n",
    "    heatmap = plot_heatmap(dist.numpy(), log_scale=True)\n",
    "    cv2.imwrite(f'heatmap_{idx}_{idx}.png', heatmap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 512])\n",
      "torch.Size([1, 64, 512])\n",
      "torch.Size([1, 64, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/gqsn1b5x75x3nstgrhp06xtw0000gp/T/ipykernel_2231/3725310736.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  dist = np.log(1 + dist)\n"
     ]
    }
   ],
   "source": [
    "for stride in [1,2,3]:\n",
    "        # Apply stride\n",
    "        stride_frames = cls_features[0][::stride]\n",
    "        stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "        if len(stride_frames) < 64:\n",
    "            continue # Skip this stride if there are not enough frames\n",
    "        stride_frames = stride_frames.unflatten(0, (-1, 64))#torch.stack(stride_frames, axis=0)#.unflatten(0, (-1, 64))#.movedim(1, 2) # Convert to N x C x D x H x W\n",
    "        #stride_frames = stride_frames.to('cpu')\n",
    "        print(stride_frames.shape)\n",
    "        dist = torch.cdist(stride_frames[0], stride_frames[0], p=2)**2\n",
    "        heatmap = plot_heatmap(dist.numpy(), log_scale=True)\n",
    "        cv2.imwrite(f'heatmap_{stride}_{stride}.png', heatmap) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    nan,  0.1632,  0.7565,  1.7438,  1.9504,  1.8161,  1.7377,  1.8566,\n",
       "         1.9492,  1.7738,  1.7761,  2.1161,  2.7009,  3.0806,  2.8743,  3.0161,\n",
       "         3.3779,  4.2877,  4.7708,  5.5370,  6.2142,  5.8301,  5.9904,  6.2961,\n",
       "         6.6460,  6.7192,  6.9608,  6.7581,  6.8010,  7.0072,  6.8008,  6.2865,\n",
       "         5.9488,  5.7946,  5.2332,  3.8308,  3.8713,  3.8520, 14.3538, 25.8715,\n",
       "        40.6224, 51.5117, 55.7323, 55.4244, 55.3719, 55.4552, 57.2446, 59.0547,\n",
       "        58.1478, 55.3545, 55.2127, 56.7046, 57.1954, 57.5956, 57.3120, 57.0352,\n",
       "        57.4644, 57.2699, 57.8301, 57.7430, 58.0325, 57.8942, 57.9166, 58.3951,\n",
       "        58.5359, 58.4131, 58.6245, 58.4574, 58.4106, 58.4121, 58.1204, 57.8090,\n",
       "        58.2526, 57.8809, 57.9353, 58.0265, 58.1120, 57.9298, 57.9554, 58.6762,\n",
       "        58.9409, 59.7615, 59.9681, 58.8786, 57.2173, 55.2582, 55.1056, 57.2741,\n",
       "        57.5580, 56.6492, 55.2717, 55.2208, 56.1625, 56.3169, 56.3218, 53.2290,\n",
       "        51.5580, 49.1340, 49.5435, 48.7004, 48.4465, 48.7366, 48.5267, 47.2544,\n",
       "        47.5419, 46.6687, 46.4420, 46.7998, 47.0730, 46.6992, 24.5136, 23.5052,\n",
       "        23.5160, 23.2493, 21.9932, 20.7628, 20.8024, 21.2986, 20.7936, 19.8709,\n",
       "        19.1975, 19.0790, 19.6032, 18.6563, 18.0687, 16.8424, 16.9544, 16.2253,\n",
       "        15.6648, 15.5265, 15.6433, 15.3829, 15.3619, 15.4301, 15.4575, 15.7068,\n",
       "        16.0471, 15.9860, 16.3080, 16.3497, 16.3059, 16.1671, 16.1423, 16.3605,\n",
       "        16.3843, 16.4464,  0.3599,  3.7339,  8.7190, 11.9927, 13.3262, 13.0114,\n",
       "        13.0103, 12.8765, 12.8311, 12.6421, 12.7523, 12.6893, 12.7612, 12.4157,\n",
       "        12.7927, 13.4270, 14.2957, 13.5694, 12.4510, 12.0457, 11.5724, 12.5212,\n",
       "        12.5860, 12.0015, 12.0668, 13.0823, 13.8766, 13.8351, 14.0191, 12.4803,\n",
       "        12.7492, 12.3647, 12.6426, 12.8204, 12.9075, 12.4901, 12.5348, 12.3017,\n",
       "        12.9445, 12.5615, 12.4497, 12.5956, 12.6051, 12.4418, 11.9495, 12.1252,\n",
       "        12.5527, 12.5332, 12.2903, 12.1154, 12.4053, 13.1556, 13.3882, 12.8691,\n",
       "        11.9755, 12.6090, 13.5800,  2.1061,  1.7790,  1.5350,  1.5270,  0.8178])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.cdist(img_features[1],img_features[1], p=2)**2\n",
    "dist1 = torch.cdist(cls_features[1],cls_features[1], p=2)**2\n",
    "dist = np.log(1 + dist)\n",
    "dist1= np.log(1 + dist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x166bbc3d0>]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(dist[0])\n",
    "plt.plot(dist1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     nan,  74.2485, 177.2854, 111.9316, 101.1504, 143.2295, 182.2933,\n",
       "        158.6210, 197.0994, 196.0265, 144.1377, 179.1146, 141.7727, 422.6034,\n",
       "        443.6486, 423.5782, 437.3733, 373.1923, 385.3989, 385.5234, 354.0729,\n",
       "        371.5658, 420.5601, 457.0677, 480.3051, 435.4335, 406.0033, 232.5043,\n",
       "        299.3757, 364.9122, 423.5060, 355.9371, 385.8215, 292.4618, 324.1901,\n",
       "        340.3060, 348.9471, 291.9451, 317.7900, 249.3714, 253.9508, 288.0504,\n",
       "        225.1104, 206.3092, 190.8108, 184.0070, 190.1059, 179.5063, 177.4777,\n",
       "        103.4275, 177.0527, 188.4703, 166.8807, 146.5547, 216.6829, 254.4276,\n",
       "        277.3436, 227.4249, 240.0393, 261.8093, 291.8750, 262.4724, 282.4844,\n",
       "        275.5892, 292.1647, 250.2932, 245.3824, 261.4182, 207.5305,  49.7943,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564, 906.1564,\n",
       "        906.1564, 906.1564])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0,::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "VIDEO_PATH = \"./xclip/data/Countix/bench press_29.mp4\"\n",
    "transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=0.5, std=0.5),\n",
    "    ])\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "raw_frames, frames = [], []\n",
    "while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "        raw_frames.append(frame)\n",
    "        frame = transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=torch.stack(frames, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-15 13:33:17 root]\u001b[0m\u001b[33m(cct.py 172)\u001b[0m: INFO load pretrained CLIP: _IncompatibleKeys(missing_keys=['class_embedding', 'positional_embedding', 'proj', 'conv1.weight', 'ln_pre.weight', 'ln_pre.bias', 'transformer.resblocks.0.message_fc.weight', 'transformer.resblocks.0.message_fc.bias', 'transformer.resblocks.0.message_ln.weight', 'transformer.resblocks.0.message_ln.bias', 'transformer.resblocks.0.message_attn.in_proj_weight', 'transformer.resblocks.0.message_attn.in_proj_bias', 'transformer.resblocks.0.message_attn.out_proj.weight', 'transformer.resblocks.0.message_attn.out_proj.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.message_fc.weight', 'transformer.resblocks.1.message_fc.bias', 'transformer.resblocks.1.message_ln.weight', 'transformer.resblocks.1.message_ln.bias', 'transformer.resblocks.1.message_attn.in_proj_weight', 'transformer.resblocks.1.message_attn.in_proj_bias', 'transformer.resblocks.1.message_attn.out_proj.weight', 'transformer.resblocks.1.message_attn.out_proj.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.message_fc.weight', 'transformer.resblocks.2.message_fc.bias', 'transformer.resblocks.2.message_ln.weight', 'transformer.resblocks.2.message_ln.bias', 'transformer.resblocks.2.message_attn.in_proj_weight', 'transformer.resblocks.2.message_attn.in_proj_bias', 'transformer.resblocks.2.message_attn.out_proj.weight', 'transformer.resblocks.2.message_attn.out_proj.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.message_fc.weight', 'transformer.resblocks.3.message_fc.bias', 'transformer.resblocks.3.message_ln.weight', 'transformer.resblocks.3.message_ln.bias', 'transformer.resblocks.3.message_attn.in_proj_weight', 'transformer.resblocks.3.message_attn.in_proj_bias', 'transformer.resblocks.3.message_attn.out_proj.weight', 'transformer.resblocks.3.message_attn.out_proj.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.message_fc.weight', 'transformer.resblocks.4.message_fc.bias', 'transformer.resblocks.4.message_ln.weight', 'transformer.resblocks.4.message_ln.bias', 'transformer.resblocks.4.message_attn.in_proj_weight', 'transformer.resblocks.4.message_attn.in_proj_bias', 'transformer.resblocks.4.message_attn.out_proj.weight', 'transformer.resblocks.4.message_attn.out_proj.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.message_fc.weight', 'transformer.resblocks.5.message_fc.bias', 'transformer.resblocks.5.message_ln.weight', 'transformer.resblocks.5.message_ln.bias', 'transformer.resblocks.5.message_attn.in_proj_weight', 'transformer.resblocks.5.message_attn.in_proj_bias', 'transformer.resblocks.5.message_attn.out_proj.weight', 'transformer.resblocks.5.message_attn.out_proj.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.message_fc.weight', 'transformer.resblocks.6.message_fc.bias', 'transformer.resblocks.6.message_ln.weight', 'transformer.resblocks.6.message_ln.bias', 'transformer.resblocks.6.message_attn.in_proj_weight', 'transformer.resblocks.6.message_attn.in_proj_bias', 'transformer.resblocks.6.message_attn.out_proj.weight', 'transformer.resblocks.6.message_attn.out_proj.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.message_fc.weight', 'transformer.resblocks.7.message_fc.bias', 'transformer.resblocks.7.message_ln.weight', 'transformer.resblocks.7.message_ln.bias', 'transformer.resblocks.7.message_attn.in_proj_weight', 'transformer.resblocks.7.message_attn.in_proj_bias', 'transformer.resblocks.7.message_attn.out_proj.weight', 'transformer.resblocks.7.message_attn.out_proj.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.message_fc.weight', 'transformer.resblocks.8.message_fc.bias', 'transformer.resblocks.8.message_ln.weight', 'transformer.resblocks.8.message_ln.bias', 'transformer.resblocks.8.message_attn.in_proj_weight', 'transformer.resblocks.8.message_attn.in_proj_bias', 'transformer.resblocks.8.message_attn.out_proj.weight', 'transformer.resblocks.8.message_attn.out_proj.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.message_fc.weight', 'transformer.resblocks.9.message_fc.bias', 'transformer.resblocks.9.message_ln.weight', 'transformer.resblocks.9.message_ln.bias', 'transformer.resblocks.9.message_attn.in_proj_weight', 'transformer.resblocks.9.message_attn.in_proj_bias', 'transformer.resblocks.9.message_attn.out_proj.weight', 'transformer.resblocks.9.message_attn.out_proj.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.message_fc.weight', 'transformer.resblocks.10.message_fc.bias', 'transformer.resblocks.10.message_ln.weight', 'transformer.resblocks.10.message_ln.bias', 'transformer.resblocks.10.message_attn.in_proj_weight', 'transformer.resblocks.10.message_attn.in_proj_bias', 'transformer.resblocks.10.message_attn.out_proj.weight', 'transformer.resblocks.10.message_attn.out_proj.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.message_fc.weight', 'transformer.resblocks.11.message_fc.bias', 'transformer.resblocks.11.message_ln.weight', 'transformer.resblocks.11.message_ln.bias', 'transformer.resblocks.11.message_attn.in_proj_weight', 'transformer.resblocks.11.message_attn.in_proj_bias', 'transformer.resblocks.11.message_attn.out_proj.weight', 'transformer.resblocks.11.message_attn.out_proj.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'ln_post.weight', 'ln_post.bias', 'mit.positional_embedding', 'mit.resblocks.0.attn.in_proj_weight', 'mit.resblocks.0.attn.in_proj_bias', 'mit.resblocks.0.attn.out_proj.weight', 'mit.resblocks.0.attn.out_proj.bias', 'mit.resblocks.0.ln_1.weight', 'mit.resblocks.0.ln_1.bias', 'mit.resblocks.0.mlp.c_fc.weight', 'mit.resblocks.0.mlp.c_fc.bias', 'mit.resblocks.0.mlp.c_proj.weight', 'mit.resblocks.0.mlp.c_proj.bias', 'mit.resblocks.0.ln_2.weight', 'mit.resblocks.0.ln_2.bias'], unexpected_keys=['visual.class_embedding', 'visual.positional_embedding', 'visual.proj', 'visual.conv1.weight', 'visual.ln_pre.weight', 'visual.ln_pre.bias', 'visual.transformer.resblocks.0.attn.in_proj_weight', 'visual.transformer.resblocks.0.attn.in_proj_bias', 'visual.transformer.resblocks.0.attn.out_proj.weight', 'visual.transformer.resblocks.0.attn.out_proj.bias', 'visual.transformer.resblocks.0.ln_1.weight', 'visual.transformer.resblocks.0.ln_1.bias', 'visual.transformer.resblocks.0.mlp.c_fc.weight', 'visual.transformer.resblocks.0.mlp.c_fc.bias', 'visual.transformer.resblocks.0.mlp.c_proj.weight', 'visual.transformer.resblocks.0.mlp.c_proj.bias', 'visual.transformer.resblocks.0.ln_2.weight', 'visual.transformer.resblocks.0.ln_2.bias', 'visual.transformer.resblocks.1.attn.in_proj_weight', 'visual.transformer.resblocks.1.attn.in_proj_bias', 'visual.transformer.resblocks.1.attn.out_proj.weight', 'visual.transformer.resblocks.1.attn.out_proj.bias', 'visual.transformer.resblocks.1.ln_1.weight', 'visual.transformer.resblocks.1.ln_1.bias', 'visual.transformer.resblocks.1.mlp.c_fc.weight', 'visual.transformer.resblocks.1.mlp.c_fc.bias', 'visual.transformer.resblocks.1.mlp.c_proj.weight', 'visual.transformer.resblocks.1.mlp.c_proj.bias', 'visual.transformer.resblocks.1.ln_2.weight', 'visual.transformer.resblocks.1.ln_2.bias', 'visual.transformer.resblocks.2.attn.in_proj_weight', 'visual.transformer.resblocks.2.attn.in_proj_bias', 'visual.transformer.resblocks.2.attn.out_proj.weight', 'visual.transformer.resblocks.2.attn.out_proj.bias', 'visual.transformer.resblocks.2.ln_1.weight', 'visual.transformer.resblocks.2.ln_1.bias', 'visual.transformer.resblocks.2.mlp.c_fc.weight', 'visual.transformer.resblocks.2.mlp.c_fc.bias', 'visual.transformer.resblocks.2.mlp.c_proj.weight', 'visual.transformer.resblocks.2.mlp.c_proj.bias', 'visual.transformer.resblocks.2.ln_2.weight', 'visual.transformer.resblocks.2.ln_2.bias', 'visual.transformer.resblocks.3.attn.in_proj_weight', 'visual.transformer.resblocks.3.attn.in_proj_bias', 'visual.transformer.resblocks.3.attn.out_proj.weight', 'visual.transformer.resblocks.3.attn.out_proj.bias', 'visual.transformer.resblocks.3.ln_1.weight', 'visual.transformer.resblocks.3.ln_1.bias', 'visual.transformer.resblocks.3.mlp.c_fc.weight', 'visual.transformer.resblocks.3.mlp.c_fc.bias', 'visual.transformer.resblocks.3.mlp.c_proj.weight', 'visual.transformer.resblocks.3.mlp.c_proj.bias', 'visual.transformer.resblocks.3.ln_2.weight', 'visual.transformer.resblocks.3.ln_2.bias', 'visual.transformer.resblocks.4.attn.in_proj_weight', 'visual.transformer.resblocks.4.attn.in_proj_bias', 'visual.transformer.resblocks.4.attn.out_proj.weight', 'visual.transformer.resblocks.4.attn.out_proj.bias', 'visual.transformer.resblocks.4.ln_1.weight', 'visual.transformer.resblocks.4.ln_1.bias', 'visual.transformer.resblocks.4.mlp.c_fc.weight', 'visual.transformer.resblocks.4.mlp.c_fc.bias', 'visual.transformer.resblocks.4.mlp.c_proj.weight', 'visual.transformer.resblocks.4.mlp.c_proj.bias', 'visual.transformer.resblocks.4.ln_2.weight', 'visual.transformer.resblocks.4.ln_2.bias', 'visual.transformer.resblocks.5.attn.in_proj_weight', 'visual.transformer.resblocks.5.attn.in_proj_bias', 'visual.transformer.resblocks.5.attn.out_proj.weight', 'visual.transformer.resblocks.5.attn.out_proj.bias', 'visual.transformer.resblocks.5.ln_1.weight', 'visual.transformer.resblocks.5.ln_1.bias', 'visual.transformer.resblocks.5.mlp.c_fc.weight', 'visual.transformer.resblocks.5.mlp.c_fc.bias', 'visual.transformer.resblocks.5.mlp.c_proj.weight', 'visual.transformer.resblocks.5.mlp.c_proj.bias', 'visual.transformer.resblocks.5.ln_2.weight', 'visual.transformer.resblocks.5.ln_2.bias', 'visual.transformer.resblocks.6.attn.in_proj_weight', 'visual.transformer.resblocks.6.attn.in_proj_bias', 'visual.transformer.resblocks.6.attn.out_proj.weight', 'visual.transformer.resblocks.6.attn.out_proj.bias', 'visual.transformer.resblocks.6.ln_1.weight', 'visual.transformer.resblocks.6.ln_1.bias', 'visual.transformer.resblocks.6.mlp.c_fc.weight', 'visual.transformer.resblocks.6.mlp.c_fc.bias', 'visual.transformer.resblocks.6.mlp.c_proj.weight', 'visual.transformer.resblocks.6.mlp.c_proj.bias', 'visual.transformer.resblocks.6.ln_2.weight', 'visual.transformer.resblocks.6.ln_2.bias', 'visual.transformer.resblocks.7.attn.in_proj_weight', 'visual.transformer.resblocks.7.attn.in_proj_bias', 'visual.transformer.resblocks.7.attn.out_proj.weight', 'visual.transformer.resblocks.7.attn.out_proj.bias', 'visual.transformer.resblocks.7.ln_1.weight', 'visual.transformer.resblocks.7.ln_1.bias', 'visual.transformer.resblocks.7.mlp.c_fc.weight', 'visual.transformer.resblocks.7.mlp.c_fc.bias', 'visual.transformer.resblocks.7.mlp.c_proj.weight', 'visual.transformer.resblocks.7.mlp.c_proj.bias', 'visual.transformer.resblocks.7.ln_2.weight', 'visual.transformer.resblocks.7.ln_2.bias', 'visual.transformer.resblocks.8.attn.in_proj_weight', 'visual.transformer.resblocks.8.attn.in_proj_bias', 'visual.transformer.resblocks.8.attn.out_proj.weight', 'visual.transformer.resblocks.8.attn.out_proj.bias', 'visual.transformer.resblocks.8.ln_1.weight', 'visual.transformer.resblocks.8.ln_1.bias', 'visual.transformer.resblocks.8.mlp.c_fc.weight', 'visual.transformer.resblocks.8.mlp.c_fc.bias', 'visual.transformer.resblocks.8.mlp.c_proj.weight', 'visual.transformer.resblocks.8.mlp.c_proj.bias', 'visual.transformer.resblocks.8.ln_2.weight', 'visual.transformer.resblocks.8.ln_2.bias', 'visual.transformer.resblocks.9.attn.in_proj_weight', 'visual.transformer.resblocks.9.attn.in_proj_bias', 'visual.transformer.resblocks.9.attn.out_proj.weight', 'visual.transformer.resblocks.9.attn.out_proj.bias', 'visual.transformer.resblocks.9.ln_1.weight', 'visual.transformer.resblocks.9.ln_1.bias', 'visual.transformer.resblocks.9.mlp.c_fc.weight', 'visual.transformer.resblocks.9.mlp.c_fc.bias', 'visual.transformer.resblocks.9.mlp.c_proj.weight', 'visual.transformer.resblocks.9.mlp.c_proj.bias', 'visual.transformer.resblocks.9.ln_2.weight', 'visual.transformer.resblocks.9.ln_2.bias', 'visual.transformer.resblocks.10.attn.in_proj_weight', 'visual.transformer.resblocks.10.attn.in_proj_bias', 'visual.transformer.resblocks.10.attn.out_proj.weight', 'visual.transformer.resblocks.10.attn.out_proj.bias', 'visual.transformer.resblocks.10.ln_1.weight', 'visual.transformer.resblocks.10.ln_1.bias', 'visual.transformer.resblocks.10.mlp.c_fc.weight', 'visual.transformer.resblocks.10.mlp.c_fc.bias', 'visual.transformer.resblocks.10.mlp.c_proj.weight', 'visual.transformer.resblocks.10.mlp.c_proj.bias', 'visual.transformer.resblocks.10.ln_2.weight', 'visual.transformer.resblocks.10.ln_2.bias', 'visual.transformer.resblocks.11.attn.in_proj_weight', 'visual.transformer.resblocks.11.attn.in_proj_bias', 'visual.transformer.resblocks.11.attn.out_proj.weight', 'visual.transformer.resblocks.11.attn.out_proj.bias', 'visual.transformer.resblocks.11.ln_1.weight', 'visual.transformer.resblocks.11.ln_1.bias', 'visual.transformer.resblocks.11.mlp.c_fc.weight', 'visual.transformer.resblocks.11.mlp.c_fc.bias', 'visual.transformer.resblocks.11.mlp.c_proj.weight', 'visual.transformer.resblocks.11.mlp.c_proj.bias', 'visual.transformer.resblocks.11.ln_2.weight', 'visual.transformer.resblocks.11.ln_2.bias', 'visual.ln_post.weight', 'visual.ln_post.bias'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_model, _ = load(None, 'ViT-B/16', \n",
    "                         device=\"cpu\", jit=False, \n",
    "                         T=len(frames), logger=logger\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames[::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=frames[:(len(frames) // 64) * 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31309824])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.view(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m    x\u001b[38;5;241m=\u001b[39membed_model(frames)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_model' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   x=embed_model(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 512])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_features = x[0]#.view(1, 64, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_features.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_featurs=x[1].mean(dim=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 768]), torch.Size([1, 64, 512]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_featurs.shape, cls_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 512]), torch.Size([64, 196, 768]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape,x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanantharaman/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/kanantharaman/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vit = torchvision.models.vit_b_16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.view(-1,3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 3, 224, 224])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict to store the activations\n",
    "activation = {}\n",
    "def getActivation(name):\n",
    "    # the hook signature\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "visual = vit.encoder.register_forward_hook(getActivation('encode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xvit = vit(images[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-20 21:49:15 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 291)\u001b[0m: DEBUG Resetting dropped connection: huggingface.co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanantharaman/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-20 21:49:15 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /google/vit-base-patch16-224/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "\u001b[32m[2024-11-20 21:49:15 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /google/vit-base-patch16-224/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 512])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=cls.view(4, 384,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(\u001b[38;5;28mcls\u001b[39m[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;28mcls\u001b[39m[\u001b[38;5;241m3\u001b[39m], p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      2\u001b[0m dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m dist)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(dist[\u001b[38;5;241m0\u001b[39m,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m200\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "dist = torch.cdist(cls[3],cls[3], p=2)**2\n",
    "dist = np.log(1 + dist)\n",
    "plt.plot(dist[0,:-200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/gqsn1b5x75x3nstgrhp06xtw0000gp/T/ipykernel_63691/3725310736.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  dist = np.log(1 + dist)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx in range(cls.shape[0]):\n",
    "    dist = torch.cdist(cls[idx], cls[idx], p=2)**2\n",
    "    heatmap = plot_heatmap(dist.numpy(), log_scale=True)\n",
    "    cv2.imwrite(f'heatmap_{idx}_{idx}.png', heatmap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19d32aa10>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dist[0,::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m----> 2\u001b[0m summary(model, input_size\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0173,  0.6985,  1.1933,  0.2160,  0.8279],\n",
       "        [ 0.0178,  0.6831,  1.1524,  0.2121,  0.7996],\n",
       "        [-0.0088,  0.6930,  1.1600,  0.2479,  0.7403],\n",
       "        [-0.0351,  0.7168,  1.1923,  0.3933,  0.7420],\n",
       "        [-0.0060,  0.7675,  1.1847,  0.3704,  0.7868]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls[0][0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(embeddings: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Plot the 1D PCA of the embeddings into an OpenCV image.\"\"\"\n",
    "    projection = PCA(n_components=1).fit_transform(embeddings).flatten()\n",
    "    projection = (projection - projection.min()) / (projection.max() - projection.min())\n",
    "    h, w = 200, len(projection) * 4\n",
    "    img = np.full((h, w, 3), 255, dtype=np.uint8)\n",
    "    y = ((1 - projection) * h).astype(np.int32)\n",
    "    x = (np.arange(len(y)) / len(y) * w).astype(np.int32)\n",
    "    pts = np.stack([x, y], axis=1).reshape((-1, 1, 2))\n",
    "    img = cv2.polylines(img, [pts], False, (102, 60, 0), 1, cv2.LINE_AA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plot_pca(x[0][2,:-150].numpy())\n",
    "img1 = plot_pca(cls[2,:-150].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(cls.shape[0]):\n",
    "    cv2.imwrite(os.path.join('./', f'pca_{idx}.png'), plot_pca(x[0][idx,:-250].numpy()))   \n",
    "    cv2.imwrite(os.path.join('./', f'pca1_{idx}.png'), plot_pca(cls[idx,:-250].numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=0\n",
    "cv2.imwrite(os.path.join('./', f'pca_openclip_{idx}.png'), plot_pca(cls[idx][:115].numpy()))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-21 13:03:17 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 291)\u001b[0m: DEBUG Resetting dropped connection: huggingface.co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanantharaman/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-21 13:03:18 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "\u001b[32m[2024-11-21 13:03:18 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "model1=CLIPVisionModel.from_pretrained('openai/clip-vit-base-patch16',torchscript=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['vision_model.embeddings.class_embedding', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.post_layernorm.weight', 'vision_model.post_layernorm.bias'])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs1 = model1(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = outputs1.last_hidden_state[:,0].view(4, 384,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for idx in range(cls1.shape[0]):\n",
    "idx=2\n",
    "cv2.imwrite(os.path.join('./', f'pca_clipvision_{idx}.png'), plot_pca(cls[idx,:-150].numpy())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timm.list_models(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-21 14:54:21 timm.models._builder]\u001b[0m\u001b[33m(_builder.py 196)\u001b[0m: INFO Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_clip_224.openai)\n",
      "\u001b[32m[2024-11-21 14:54:21 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 291)\u001b[0m: DEBUG Resetting dropped connection: huggingface.co\n",
      "\u001b[32m[2024-11-21 14:54:22 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /timm/vit_base_patch16_clip_224.openai/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "\u001b[32m[2024-11-21 14:54:22 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /timm/vit_base_patch16_clip_224.openai/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "\u001b[32m[2024-11-21 14:54:22 filelock]\u001b[0m\u001b[33m(_api.py 172)\u001b[0m: DEBUG Attempting to acquire lock 5599694864 on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.openai/53b401837e5baa82115d3b6db60c6fff43cfd1a6412e48ed0193d54a69d2f993.lock\n",
      "\u001b[32m[2024-11-21 14:54:22 filelock]\u001b[0m\u001b[33m(_api.py 176)\u001b[0m: DEBUG Lock 5599694864 acquired on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.openai/53b401837e5baa82115d3b6db60c6fff43cfd1a6412e48ed0193d54a69d2f993.lock\n",
      "\u001b[32m[2024-11-21 14:54:22 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 291)\u001b[0m: DEBUG Resetting dropped connection: cdn-lfs.hf.co\n",
      "\u001b[32m[2024-11-21 14:54:22 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://cdn-lfs.hf.co:443 \"GET /repos/7e/ab/7eab90d82e99d6c1aca12c938f8d8ce7a15ecd7a09ad769671bb05d726e1ca91/53b401837e5baa82115d3b6db60c6fff43cfd1a6412e48ed0193d54a69d2f993?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732488115&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjQ4ODExNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83ZS9hYi83ZWFiOTBkODJlOTlkNmMxYWNhMTJjOTM4ZjhkOGNlN2ExNWVjZDdhMDlhZDc2OTY3MWJiMDVkNzI2ZTFjYTkxLzUzYjQwMTgzN2U1YmFhODIxMTVkM2I2ZGI2MGM2ZmZmNDNjZmQxYTY0MTJlNDhlZDAxOTNkNTRhNjlkMmY5OTM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=vb4qq74C93MlVo9s07~HzsnCnH2VGYNTDdfeI3TweDJrc9Z9WDzntAUWdkPmZ5~QosNp86cDd2-vwQcoxyhWvj9TwBxT58W6-jqiwQQgZg~4dGpBv47GF7slIn9dHyEUVOtl8TfkXB73~~0ozxcl7QuRaYnTxRN3UwWfztmEVSjOsKxBNemVObMQ6Ex~yMXTRtJIZEEdYlw3vcEbqLX0igudu6Y2kxFTLst62Hf7~L~FZSbdi4QF4f4XPy47i4hN~HZm2S6knmwwaS4uOadFQoeT0PKsKowkQKWnEbdMBJR~dLzom2iwrEwaOVYl8msj1u63220OiMGGHQM5MxU3dw__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/1.1\" 200 598594981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e7c39c793548b995cb4cd685d4f5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-21 14:56:22 filelock]\u001b[0m\u001b[33m(_api.py 209)\u001b[0m: DEBUG Attempting to release lock 5599694864 on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.openai/53b401837e5baa82115d3b6db60c6fff43cfd1a6412e48ed0193d54a69d2f993.lock\n",
      "\u001b[32m[2024-11-21 14:56:22 filelock]\u001b[0m\u001b[33m(_api.py 212)\u001b[0m: DEBUG Lock 5599694864 released on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.openai/53b401837e5baa82115d3b6db60c6fff43cfd1a6412e48ed0193d54a69d2f993.lock\n",
      "\u001b[32m[2024-11-21 14:56:22 timm.models._hub]\u001b[0m\u001b[33m(_hub.py 193)\u001b[0m: DEBUG [timm/vit_base_patch16_clip_224.openai] Safe alternative not found for 'pytorch_model.bin'. Loading weights using default pytorch.\n"
     ]
    }
   ],
   "source": [
    "model4 = timm.create_model('vit_base_patch16_clip_224.openai', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'norm_pre.weight', 'norm_pre.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclip.clip.clip import load_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-22 21:24:12 root]\u001b[0m\u001b[33m(factory.py 296)\u001b[0m: INFO Loaded ViT-B-16 model config.\n",
      "\u001b[32m[2024-11-22 21:24:14 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 291)\u001b[0m: DEBUG Resetting dropped connection: huggingface.co\n",
      "\u001b[32m[2024-11-22 21:24:14 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://huggingface.co:443 \"HEAD /timm/vit_base_patch16_clip_224.laion400m_e31/resolve/main/open_clip_model.safetensors HTTP/1.1\" 302 0\n",
      "\u001b[32m[2024-11-22 21:24:14 filelock]\u001b[0m\u001b[33m(_api.py 172)\u001b[0m: DEBUG Attempting to acquire lock 7412693776 on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.laion400m_e31/e94aaa95b532107ed4453989dff56def08fc93f60df77add1e1087a51624559e.lock\n",
      "\u001b[32m[2024-11-22 21:24:14 filelock]\u001b[0m\u001b[33m(_api.py 176)\u001b[0m: DEBUG Lock 7412693776 acquired on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.laion400m_e31/e94aaa95b532107ed4453989dff56def08fc93f60df77add1e1087a51624559e.lock\n",
      "\u001b[32m[2024-11-22 21:24:14 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 1021)\u001b[0m: DEBUG Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443\n",
      "\u001b[32m[2024-11-22 21:24:14 urllib3.connectionpool]\u001b[0m\u001b[33m(connectionpool.py 474)\u001b[0m: DEBUG https://cdn-lfs-us-1.hf.co:443 \"GET /repos/c9/27/c927a242e5a8ed7ffc76932a4d3d613c05b961be33a0cf1b3ed273ce8eeefc7a/e94aaa95b532107ed4453989dff56def08fc93f60df77add1e1087a51624559e?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27open_clip_model.safetensors%3B+filename%3D%22open_clip_model.safetensors%22%3B&Expires=1732598654&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjU5ODY1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2M5LzI3L2M5MjdhMjQyZTVhOGVkN2ZmYzc2OTMyYTRkM2Q2MTNjMDViOTYxYmUzM2EwY2YxYjNlZDI3M2NlOGVlZWZjN2EvZTk0YWFhOTViNTMyMTA3ZWQ0NDUzOTg5ZGZmNTZkZWYwOGZjOTNmNjBkZjc3YWRkMWUxMDg3YTUxNjI0NTU5ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=b0A11SUF-6WLqxhyJsMGXmPP-EWYNIWb6V9-uu1oHFhjcGTlCW0bSmqJdinXgHT1DGshgG71~cqxwcgF-FDH8stqGwsGeVOQ7Cn3zu9q7L74DpOiraLpnR6iKBQNe7YDI~hGx64laBpVtf~zcJp3BEmPzS2e5gFSbfq8UFYlZ20AuRzVs594gbOoW-P-v5pknBgPsgBG3qrZcPchHbNssTa4vtKIB1AfzAFICYdIMKEjXFdEBNEam1KOCwEQ2Qd2JRXcvK~fnmIlN-C5ASjHpxWFKquxrw~YrEnhB8rKrrUnZXX7XTrJC9UO1k7h~tAtwb6TfHYzrhdITA29Ibh-MA__&Key-Pair-Id=K24J24Z295AEI9 HTTP/1.1\" 200 598516980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64b60c816fa4572b6fe4de8bcb321bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-11-22 21:25:24 filelock]\u001b[0m\u001b[33m(_api.py 209)\u001b[0m: DEBUG Attempting to release lock 7412693776 on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.laion400m_e31/e94aaa95b532107ed4453989dff56def08fc93f60df77add1e1087a51624559e.lock\n",
      "\u001b[32m[2024-11-22 21:25:24 filelock]\u001b[0m\u001b[33m(_api.py 212)\u001b[0m: DEBUG Lock 7412693776 released on /Users/kanantharaman/.cache/huggingface/hub/.locks/models--timm--vit_base_patch16_clip_224.laion400m_e31/e94aaa95b532107ed4453989dff56def08fc93f60df77add1e1087a51624559e.lock\n",
      "\u001b[32m[2024-11-22 21:25:24 root]\u001b[0m\u001b[33m(factory.py 383)\u001b[0m: INFO Loading pretrained ViT-B-16 weights (laion400m_e31).\n"
     ]
    }
   ],
   "source": [
    "model = load_vit(None,'ViT-B-16', device=\"cpu\", jit=False,pretrained='laion400m_e31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "CLIPVision                                         [1536, 512]               --\n",
       "VisionTransformer: 1-1                           [1536, 512]               545,280\n",
       "    Conv2d: 2-1                                 [1536, 768, 14, 14]       589,824\n",
       "    LayerNorm: 2-2                              [1536, 197, 768]          1,536\n",
       "    Transformer: 2-3                            [197, 1536, 768]          --\n",
       "        Sequential: 3-1                        [197, 1536, 768]          85,054,464\n",
       "    LayerNorm: 2-4                              [1536, 768]               1,536\n",
       "====================================================================================================\n",
       "Total params: 86,192,640\n",
       "Trainable params: 86,192,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 188.75\n",
       "====================================================================================================\n",
       "Input size (MB): 924.84\n",
       "Forward/backward pass size (MB): 159884.77\n",
       "Params size (MB): 229.20\n",
       "Estimated Total Size (MB): 161038.81\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([k for k in model.state_dict().keys() if k.startswith(\"visual.\") and k.endswith(\".attn.in_proj_weight\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = outputs.view(4,384,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 512])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "CLIPVisionModel                                              [1536, 768]               --\n",
       "CLIPVisionTransformer: 1-1                                 [1536, 768]               --\n",
       "    CLIPVisionEmbeddings: 2-1                             [1536, 197, 768]          768\n",
       "        Conv2d: 3-1                                      [1536, 768, 14, 14]       589,824\n",
       "        Embedding: 3-2                                   [1, 197, 768]             151,296\n",
       "    LayerNorm: 2-2                                        [1536, 197, 768]          1,536\n",
       "    CLIPEncoder: 2-3                                      [1536, 197, 768]          --\n",
       "        ModuleList: 3-3                                  --                        85,054,464\n",
       "    LayerNorm: 2-4                                        [1536, 768]               1,536\n",
       "==============================================================================================================\n",
       "Total params: 85,799,424\n",
       "Trainable params: 85,799,424\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 308.22\n",
       "==============================================================================================================\n",
       "Input size (MB): 924.84\n",
       "Forward/backward pass size (MB): 249123.99\n",
       "Params size (MB): 343.19\n",
       "Estimated Total Size (MB): 250392.03\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model1, input_size=images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual.class_embedding torch.Size([768])\n",
      "visual.positional_embedding torch.Size([197, 768])\n",
      "visual.proj torch.Size([768, 512])\n",
      "visual.conv1.weight torch.Size([768, 3, 16, 16])\n",
      "visual.ln_pre.weight torch.Size([768])\n",
      "visual.ln_pre.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.0.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.0.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.0.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.0.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.0.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.0.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.1.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.1.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.1.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.1.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.1.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.1.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.2.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.2.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.2.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.2.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.2.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.2.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.3.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.3.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.3.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.3.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.3.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.3.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.4.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.4.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.4.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.4.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.4.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.4.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.5.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.5.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.5.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.5.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.5.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.5.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.6.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.6.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.6.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.6.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.6.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.6.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.7.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.7.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.7.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.7.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.7.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.7.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.8.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.8.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.8.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.8.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.8.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.8.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.9.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.9.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.9.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.9.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.9.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.9.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.10.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.10.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.10.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.10.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.10.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.10.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.11.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.11.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.11.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.11.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.11.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.11.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_2.bias torch.Size([768])\n",
      "visual.ln_post.weight torch.Size([768])\n",
      "visual.ln_post.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 3, 224, 224])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.view(4,3,224,224).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536, 768, 14, 14])\n",
      "torch.Size([1536, 768, 196])\n",
      "torch.Size([1536, 196, 768])\n",
      "torch.Size([1536, 197, 768])\n",
      "torch.Size([1536, 197, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "CrossFrameCommunicationTransformerv1               [4, 384, 512]             545,280\n",
       "Conv2d: 1-1                                      [1536, 768, 14, 14]       589,824\n",
       "LayerNorm: 1-2                                   [1536, 197, 768]          1,536\n",
       "Transformer: 1-3                                 [197, 1536, 768]          --\n",
       "    Sequential: 2-1                             [197, 1536, 768]          --\n",
       "        CrossFramelAttentionBlock: 3-1         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-2         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-3         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-4         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-5         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-6         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-7         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-8         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-9         [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-10        [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-11        [197, 1536, 768]          10,042,368\n",
       "        CrossFramelAttentionBlock: 3-12        [197, 1536, 768]          10,042,368\n",
       "LayerNorm: 1-4                                   [1536, 768]               1,536\n",
       "MultiframeIntegrationTransformer: 1-5            [4, 384, 512]             196,608\n",
       "    Sequential: 2-2                             [384, 4, 512]             --\n",
       "        ResidualAttentionBlock: 3-13           [384, 4, 512]             3,152,384\n",
       "        ResidualAttentionBlock: 3-14           [384, 4, 512]             3,152,384\n",
       "        ResidualAttentionBlock: 3-15           [384, 4, 512]             3,152,384\n",
       "        ResidualAttentionBlock: 3-16           [384, 4, 512]             3,152,384\n",
       "MultiframeIntegrationTransformer: 1-6            [4, 384, 512]             (recursive)\n",
       "    Sequential: 2-3                             [384, 4, 512]             (recursive)\n",
       "        ResidualAttentionBlock: 3-17           [384, 4, 512]             (recursive)\n",
       "        ResidualAttentionBlock: 3-18           [384, 4, 512]             (recursive)\n",
       "        ResidualAttentionBlock: 3-19           [384, 4, 512]             (recursive)\n",
       "        ResidualAttentionBlock: 3-20           [384, 4, 512]             (recursive)\n",
       "====================================================================================================\n",
       "Total params: 134,452,736\n",
       "Trainable params: 134,452,736\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 195.25\n",
       "====================================================================================================\n",
       "Input size (MB): 924.84\n",
       "Forward/backward pass size (MB): 160803.32\n",
       "Params size (MB): 291.25\n",
       "Estimated Total Size (MB): 162019.41\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(embed_model, input_size=images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_date = torch.load(\"/Users/kanantharaman/.cache/clip/ViT-B-16.pt\",map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_embedding torch.Size([77, 512])\n",
      "text_projection torch.Size([512, 512])\n",
      "logit_scale torch.Size([])\n",
      "visual.class_embedding torch.Size([768])\n",
      "visual.positional_embedding torch.Size([197, 768])\n",
      "visual.proj torch.Size([768, 512])\n",
      "visual.conv1.weight torch.Size([768, 3, 16, 16])\n",
      "visual.ln_pre.weight torch.Size([768])\n",
      "visual.ln_pre.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.0.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.0.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.0.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.0.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.0.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.0.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.0.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.1.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.1.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.1.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.1.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.1.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.1.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.1.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.2.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.2.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.2.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.2.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.2.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.2.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.2.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.3.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.3.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.3.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.3.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.3.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.3.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.3.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.4.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.4.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.4.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.4.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.4.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.4.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.4.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.5.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.5.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.5.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.5.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.5.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.5.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.5.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.6.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.6.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.6.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.6.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.6.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.6.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.6.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.7.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.7.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.7.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.7.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.7.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.7.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.7.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.8.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.8.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.8.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.8.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.8.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.8.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.8.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.9.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.9.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.9.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.9.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.9.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.9.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.9.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.10.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.10.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.10.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.10.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.10.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.10.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.10.ln_2.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.attn.in_proj_weight torch.Size([2304, 768])\n",
      "visual.transformer.resblocks.11.attn.in_proj_bias torch.Size([2304])\n",
      "visual.transformer.resblocks.11.attn.out_proj.weight torch.Size([768, 768])\n",
      "visual.transformer.resblocks.11.attn.out_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_1.weight torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_1.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.mlp.c_fc.weight torch.Size([3072, 768])\n",
      "visual.transformer.resblocks.11.mlp.c_fc.bias torch.Size([3072])\n",
      "visual.transformer.resblocks.11.mlp.c_proj.weight torch.Size([768, 3072])\n",
      "visual.transformer.resblocks.11.mlp.c_proj.bias torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_2.weight torch.Size([768])\n",
      "visual.transformer.resblocks.11.ln_2.bias torch.Size([768])\n",
      "visual.ln_post.weight torch.Size([768])\n",
      "visual.ln_post.bias torch.Size([768])\n",
      "transformer.resblocks.0.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.0.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.0.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.0.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.0.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.0.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.0.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.0.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.0.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.0.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.0.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.0.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.1.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.1.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.1.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.1.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.1.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.1.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.1.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.1.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.1.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.1.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.1.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.1.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.2.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.2.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.2.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.2.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.2.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.2.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.2.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.2.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.2.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.2.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.2.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.2.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.3.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.3.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.3.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.3.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.3.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.3.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.3.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.3.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.3.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.3.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.3.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.3.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.4.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.4.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.4.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.4.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.4.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.4.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.4.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.4.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.4.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.4.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.4.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.4.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.5.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.5.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.5.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.5.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.5.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.5.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.5.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.5.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.5.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.5.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.5.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.5.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.6.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.6.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.6.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.6.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.6.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.6.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.6.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.6.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.6.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.6.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.6.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.6.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.7.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.7.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.7.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.7.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.7.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.7.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.7.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.7.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.7.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.7.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.7.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.7.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.8.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.8.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.8.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.8.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.8.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.8.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.8.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.8.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.8.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.8.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.8.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.8.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.9.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.9.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.9.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.9.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.9.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.9.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.9.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.9.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.9.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.9.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.9.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.9.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.10.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.10.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.10.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.10.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.10.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.10.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.10.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.10.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.10.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.10.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.10.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.10.ln_2.bias torch.Size([512])\n",
      "transformer.resblocks.11.attn.in_proj_weight torch.Size([1536, 512])\n",
      "transformer.resblocks.11.attn.in_proj_bias torch.Size([1536])\n",
      "transformer.resblocks.11.attn.out_proj.weight torch.Size([512, 512])\n",
      "transformer.resblocks.11.attn.out_proj.bias torch.Size([512])\n",
      "transformer.resblocks.11.ln_1.weight torch.Size([512])\n",
      "transformer.resblocks.11.ln_1.bias torch.Size([512])\n",
      "transformer.resblocks.11.mlp.c_fc.weight torch.Size([2048, 512])\n",
      "transformer.resblocks.11.mlp.c_fc.bias torch.Size([2048])\n",
      "transformer.resblocks.11.mlp.c_proj.weight torch.Size([512, 2048])\n",
      "transformer.resblocks.11.mlp.c_proj.bias torch.Size([512])\n",
      "transformer.resblocks.11.ln_2.weight torch.Size([512])\n",
      "transformer.resblocks.11.ln_2.bias torch.Size([512])\n",
      "token_embedding.weight torch.Size([49408, 512])\n",
      "ln_final.weight torch.Size([512])\n",
      "ln_final.bias torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_date.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
